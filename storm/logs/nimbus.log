2023-03-28 10:38:56.838 o.a.s.v.ConfigValidation main [INFO] Will use [class org.apache.storm.DaemonConfig, class org.apache.storm.Config] for validation
2023-03-28 10:38:56.987 o.a.s.z.AclEnforcement main [INFO] SECURITY IS DISABLED NO FURTHER CHECKS...
2023-03-28 10:38:57.089 o.a.s.m.r.RocksDbStore main [INFO] Opening RocksDB from /home/user/Storm/storm/storm_rocks
2023-03-28 10:38:57.105 o.a.s.n.NimbusInfo main [INFO] Nimbus figures out its name to Ubuntu.myguest.virtualbox.org
2023-03-28 10:38:57.239 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT
2023-03-28 10:38:57.239 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:host.name=Ubuntu.myguest.virtualbox.org
2023-03-28 10:38:57.239 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.version=11.0.18
2023-03-28 10:38:57.239 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.vendor=Ubuntu
2023-03-28 10:38:57.240 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64
2023-03-28 10:38:57.240 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.class.path=/home/user/Storm/storm/*:/home/user/Storm/storm/lib/nimbus-jose-jwt-4.41.1.jar:/home/user/Storm/storm/lib/netty-resolver-4.1.30.Final.jar:/home/user/Storm/storm/lib/commons-codec-1.11.jar:/home/user/Storm/storm/lib/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/Storm/storm/lib/jackson-databind-2.10.0.jar:/home/user/Storm/storm/lib/jakarta.xml.bind-api-2.3.2.jar:/home/user/Storm/storm/lib/netty-codec-4.1.30.Final.jar:/home/user/Storm/storm/lib/kryo-3.0.3.jar:/home/user/Storm/storm/lib/json-simple-1.1.jar:/home/user/Storm/storm/lib/jetty-http-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/zookeeper-3.5.9.jar:/home/user/Storm/storm/lib/log4j-over-slf4j-1.7.36.jar:/home/user/Storm/storm/lib/jetty-server-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/chill-java-0.8.0.jar:/home/user/Storm/storm/lib/commons-io-2.6.jar:/home/user/Storm/storm/lib/jetty-security-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/checker-qual-2.5.2.jar:/home/user/Storm/storm/lib/error_prone_annotations-2.2.0.jar:/home/user/Storm/storm/lib/storm-client-2.4.0.jar:/home/user/Storm/storm/lib/netty-handler-4.1.30.Final.jar:/home/user/Storm/storm/lib/curator-client-4.3.0.jar:/home/user/Storm/storm/lib/metrics-graphite-3.2.6.jar:/home/user/Storm/storm/lib/commons-collections-3.2.2.jar:/home/user/Storm/storm/lib/kryo-shaded-3.0.3.jar:/home/user/Storm/storm/lib/netty-common-4.1.30.Final.jar:/home/user/Storm/storm/lib/hadoop-auth-2.8.5.jar:/home/user/Storm/storm/lib/storm-clojure-2.4.0.jar:/home/user/Storm/storm/lib/minlog-1.3.0.jar:/home/user/Storm/storm/lib/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/Storm/storm/lib/core.specs.alpha-0.2.44.jar:/home/user/Storm/storm/lib/clojure-1.10.0.jar:/home/user/Storm/storm/lib/jetty-servlets-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/commons-compress-1.18.jar:/home/user/Storm/storm/lib/log4j-api-2.17.1.jar:/home/user/Storm/storm/lib/storm-shaded-deps-2.4.0.jar:/home/user/Storm/storm/lib/audience-annotations-0.5.0.jar:/home/user/Storm/storm/lib/commons-exec-1.3.jar:/home/user/Storm/storm/lib/javax.servlet-api-3.1.0.jar:/home/user/Storm/storm/lib/javax.annotation-api-1.3.2.jar:/home/user/Storm/storm/lib/tools.logging-0.2.3.jar:/home/user/Storm/storm/lib/objenesis-2.1.jar:/home/user/Storm/storm/lib/rocksdbjni-5.18.4.jar:/home/user/Storm/storm/lib/log4j-slf4j-impl-2.17.1.jar:/home/user/Storm/storm/lib/netty-transport-4.1.30.Final.jar:/home/user/Storm/storm/lib/jackson-annotations-2.10.0.jar:/home/user/Storm/storm/lib/httpcore-4.4.10.jar:/home/user/Storm/storm/lib/httpclient-4.5.6.jar:/home/user/Storm/storm/lib/jetty-util-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/spec.alpha-0.2.176.jar:/home/user/Storm/storm/lib/animal-sniffer-annotations-1.17.jar:/home/user/Storm/storm/lib/j2objc-annotations-1.1.jar:/home/user/Storm/storm/lib/jetty-continuation-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/storm-core-2.4.0.jar:/home/user/Storm/storm/lib/accessors-smart-1.2.jar:/home/user/Storm/storm/lib/jsr305-3.0.2.jar:/home/user/Storm/storm/lib/commons-fileupload-1.3.3.jar:/home/user/Storm/storm/lib/jackson-dataformat-smile-2.10.0.jar:/home/user/Storm/storm/lib/netty-buffer-4.1.30.Final.jar:/home/user/Storm/storm/lib/jline-0.9.94.jar:/home/user/Storm/storm/lib/curator-framework-4.3.0.jar:/home/user/Storm/storm/lib/metrics-core-3.2.6.jar:/home/user/Storm/storm/lib/jetty-servlet-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/json-smart-2.3.jar:/home/user/Storm/storm/lib/guava-27.0.1-jre.jar:/home/user/Storm/storm/lib/failureaccess-1.0.1.jar:/home/user/Storm/storm/lib/jackson-core-2.10.0.jar:/home/user/Storm/storm/lib/jcip-annotations-1.0-1.jar:/home/user/Storm/storm/lib/commons-logging-1.2.jar:/home/user/Storm/storm/lib/carbonite-1.5.0.jar:/home/user/Storm/storm/lib/asm-5.0.3.jar:/home/user/Storm/storm/lib/slf4j-api-1.7.36.jar:/home/user/Storm/storm/lib/metrics-jvm-3.2.6.jar:/home/user/Storm/storm/lib/jakarta.activation-api-1.2.1.jar:/home/user/Storm/storm/lib/reflectasm-1.10.1.jar:/home/user/Storm/storm/lib/zookeeper-jute-3.5.9.jar:/home/user/Storm/storm/lib/snakeyaml-1.26.jar:/home/user/Storm/storm/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/user/Storm/storm/lib/log4j-core-2.17.1.jar:/home/user/Storm/storm/lib/commons-lang-2.6.jar:/home/user/Storm/storm/lib/storm-server-2.4.0.jar:/home/user/Storm/storm/lib/commons-cli-1.4.jar:/home/user/Storm/storm/lib/jetty-io-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/joda-time-2.3.jar:/home/user/Storm/storm/lib/jakarta.activation-1.2.1.jar:/home/user/Storm/storm/extlib/*:/home/user/Storm/storm/extlib-daemon/*:/home/user/Storm/storm/conf
2023-03-28 10:38:57.241 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64
2023-03-28 10:38:57.241 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.io.tmpdir=/tmp
2023-03-28 10:38:57.241 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.compiler=<NA>
2023-03-28 10:38:57.241 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.name=Linux
2023-03-28 10:38:57.241 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.arch=amd64
2023-03-28 10:38:57.242 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.version=5.19.0-35-generic
2023-03-28 10:38:57.242 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.name=user
2023-03-28 10:38:57.242 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.home=/home/user
2023-03-28 10:38:57.242 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.dir=/home/user/Storm/storm
2023-03-28 10:38:57.242 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.free=38MB
2023-03-28 10:38:57.242 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.max=1024MB
2023-03-28 10:38:57.242 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.total=64MB
2023-03-28 10:38:57.244 o.a.s.s.o.a.c.u.Compatibility main [INFO] Using emulated InjectSessionExpiration
2023-03-28 10:38:57.282 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-03-28 10:38:57.282 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-03-28 10:38:57.288 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@3e598df9
2023-03-28 10:38:57.293 o.a.s.s.o.a.z.c.X509Util main [INFO] Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2023-03-28 10:38:57.301 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-03-28 10:38:57.309 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-03-28 10:38:57.337 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:38:57.340 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-03-28 10:38:57.351 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:38:58.456 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:38:58.458 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:38:59.561 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:38:59.563 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:00.686 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:00.687 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:01.789 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:01.790 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:02.892 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:02.893 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:03.995 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:03.996 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:05.098 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:05.099 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:06.210 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:06.213 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:07.333 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:07.335 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:08.447 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:08.448 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:09.556 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:09.557 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:10.679 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:10.680 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:11.793 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:11.795 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:12.912 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:12.916 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:14.043 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:14.046 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:15.154 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:15.156 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:16.275 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:16.277 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:17.395 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:17.397 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:17.427 o.a.s.s.o.a.c.f.s.ConnectionStateManager Curator-Framework-0 [INFO] State change: SUSPENDED
2023-03-28 10:39:17.430 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [ERROR] Background operation retry gave up
org.apache.storm.shade.org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss
	at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:102) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkBackgroundRetry(CuratorFrameworkImpl.java:862) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:990) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:943) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:66) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:346) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-03-28 10:39:17.479 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [ERROR] Background retry gave up
org.apache.storm.shade.org.apache.curator.CuratorConnectionLossException: KeeperErrorCode = ConnectionLoss
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:972) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:943) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:66) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:346) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-03-28 10:39:18.499 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:39:18.500 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:39:18.601 o.a.s.u.Utils main [ERROR] Received error in thread main.. terminating server...
java.lang.Error: java.lang.RuntimeException: org.apache.storm.shade.org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /storm
	at org.apache.storm.utils.Utils.handleUncaughtException(Utils.java:663) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.utils.Utils.handleUncaughtException(Utils.java:667) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.utils.Utils.lambda$createDefaultUncaughtExceptionHandler$2(Utils.java:1047) ~[storm-client-2.4.0.jar:2.4.0]
	at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1055) [?:?]
	at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1050) [?:?]
	at java.lang.Thread.dispatchUncaughtException(Thread.java:1997) [?:?]
Caused by: java.lang.RuntimeException: org.apache.storm.shade.org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /storm
	at org.apache.storm.utils.Utils.wrapInRuntime(Utils.java:493) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:147) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ZKStateStorage.<init>(ZKStateStorage.java:65) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ZKStateStorageFactory.mkStore(ZKStateStorageFactory.java:30) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ClusterUtils.mkStateStorageImpl(ClusterUtils.java:318) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ClusterUtils.mkStormClusterStateImpl(ClusterUtils.java:301) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ClusterUtils.mkStormClusterState(ClusterUtils.java:286) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.makeStormClusterState(Nimbus.java:1581) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.<init>(Nimbus.java:562) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.<init>(Nimbus.java:479) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.<init>(Nimbus.java:473) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.launchServer(Nimbus.java:1535) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.launch(Nimbus.java:1560) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.main(Nimbus.java:1565) ~[storm-server-2.4.0.jar:2.4.0]
Caused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /storm
	at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:102) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:54) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:2021) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl$3.call(ExistsBuilderImpl.java:268) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl$3.call(ExistsBuilderImpl.java:257) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.connection.StandardConnectionHandlingPolicy.callWithRetry(StandardConnectionHandlingPolicy.java:67) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:81) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl.pathInForegroundStandard(ExistsBuilderImpl.java:254) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl.pathInForeground(ExistsBuilderImpl.java:247) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl.forPath(ExistsBuilderImpl.java:206) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl.forPath(ExistsBuilderImpl.java:35) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:144) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ZKStateStorage.<init>(ZKStateStorage.java:65) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ZKStateStorageFactory.mkStore(ZKStateStorageFactory.java:30) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ClusterUtils.mkStateStorageImpl(ClusterUtils.java:318) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ClusterUtils.mkStormClusterStateImpl(ClusterUtils.java:301) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ClusterUtils.mkStormClusterState(ClusterUtils.java:286) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.makeStormClusterState(Nimbus.java:1581) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.<init>(Nimbus.java:562) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.<init>(Nimbus.java:479) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.<init>(Nimbus.java:473) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.launchServer(Nimbus.java:1535) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.launch(Nimbus.java:1560) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.main(Nimbus.java:1565) ~[storm-server-2.4.0.jar:2.4.0]
2023-03-28 10:42:36.325 o.a.s.v.ConfigValidation main [INFO] Will use [class org.apache.storm.DaemonConfig, class org.apache.storm.Config] for validation
2023-03-28 10:42:36.457 o.a.s.z.AclEnforcement main [INFO] SECURITY IS DISABLED NO FURTHER CHECKS...
2023-03-28 10:42:36.552 o.a.s.m.r.RocksDbStore main [INFO] Opening RocksDB from /home/user/Storm/storm/storm_rocks
2023-03-28 10:42:36.571 o.a.s.n.NimbusInfo main [INFO] Nimbus figures out its name to Ubuntu.myguest.virtualbox.org
2023-03-28 10:42:36.663 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT
2023-03-28 10:42:36.663 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:host.name=Ubuntu.myguest.virtualbox.org
2023-03-28 10:42:36.663 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.version=11.0.18
2023-03-28 10:42:36.663 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.vendor=Ubuntu
2023-03-28 10:42:36.663 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64
2023-03-28 10:42:36.663 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.class.path=/home/user/Storm/storm/*:/home/user/Storm/storm/lib/nimbus-jose-jwt-4.41.1.jar:/home/user/Storm/storm/lib/netty-resolver-4.1.30.Final.jar:/home/user/Storm/storm/lib/commons-codec-1.11.jar:/home/user/Storm/storm/lib/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/Storm/storm/lib/jackson-databind-2.10.0.jar:/home/user/Storm/storm/lib/jakarta.xml.bind-api-2.3.2.jar:/home/user/Storm/storm/lib/netty-codec-4.1.30.Final.jar:/home/user/Storm/storm/lib/kryo-3.0.3.jar:/home/user/Storm/storm/lib/json-simple-1.1.jar:/home/user/Storm/storm/lib/jetty-http-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/zookeeper-3.5.9.jar:/home/user/Storm/storm/lib/log4j-over-slf4j-1.7.36.jar:/home/user/Storm/storm/lib/jetty-server-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/chill-java-0.8.0.jar:/home/user/Storm/storm/lib/commons-io-2.6.jar:/home/user/Storm/storm/lib/jetty-security-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/checker-qual-2.5.2.jar:/home/user/Storm/storm/lib/error_prone_annotations-2.2.0.jar:/home/user/Storm/storm/lib/storm-client-2.4.0.jar:/home/user/Storm/storm/lib/netty-handler-4.1.30.Final.jar:/home/user/Storm/storm/lib/curator-client-4.3.0.jar:/home/user/Storm/storm/lib/metrics-graphite-3.2.6.jar:/home/user/Storm/storm/lib/commons-collections-3.2.2.jar:/home/user/Storm/storm/lib/kryo-shaded-3.0.3.jar:/home/user/Storm/storm/lib/netty-common-4.1.30.Final.jar:/home/user/Storm/storm/lib/hadoop-auth-2.8.5.jar:/home/user/Storm/storm/lib/storm-clojure-2.4.0.jar:/home/user/Storm/storm/lib/minlog-1.3.0.jar:/home/user/Storm/storm/lib/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/Storm/storm/lib/core.specs.alpha-0.2.44.jar:/home/user/Storm/storm/lib/clojure-1.10.0.jar:/home/user/Storm/storm/lib/jetty-servlets-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/commons-compress-1.18.jar:/home/user/Storm/storm/lib/log4j-api-2.17.1.jar:/home/user/Storm/storm/lib/storm-shaded-deps-2.4.0.jar:/home/user/Storm/storm/lib/audience-annotations-0.5.0.jar:/home/user/Storm/storm/lib/commons-exec-1.3.jar:/home/user/Storm/storm/lib/javax.servlet-api-3.1.0.jar:/home/user/Storm/storm/lib/javax.annotation-api-1.3.2.jar:/home/user/Storm/storm/lib/tools.logging-0.2.3.jar:/home/user/Storm/storm/lib/objenesis-2.1.jar:/home/user/Storm/storm/lib/rocksdbjni-5.18.4.jar:/home/user/Storm/storm/lib/log4j-slf4j-impl-2.17.1.jar:/home/user/Storm/storm/lib/netty-transport-4.1.30.Final.jar:/home/user/Storm/storm/lib/jackson-annotations-2.10.0.jar:/home/user/Storm/storm/lib/httpcore-4.4.10.jar:/home/user/Storm/storm/lib/httpclient-4.5.6.jar:/home/user/Storm/storm/lib/jetty-util-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/spec.alpha-0.2.176.jar:/home/user/Storm/storm/lib/animal-sniffer-annotations-1.17.jar:/home/user/Storm/storm/lib/j2objc-annotations-1.1.jar:/home/user/Storm/storm/lib/jetty-continuation-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/storm-core-2.4.0.jar:/home/user/Storm/storm/lib/accessors-smart-1.2.jar:/home/user/Storm/storm/lib/jsr305-3.0.2.jar:/home/user/Storm/storm/lib/commons-fileupload-1.3.3.jar:/home/user/Storm/storm/lib/jackson-dataformat-smile-2.10.0.jar:/home/user/Storm/storm/lib/netty-buffer-4.1.30.Final.jar:/home/user/Storm/storm/lib/jline-0.9.94.jar:/home/user/Storm/storm/lib/curator-framework-4.3.0.jar:/home/user/Storm/storm/lib/metrics-core-3.2.6.jar:/home/user/Storm/storm/lib/jetty-servlet-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/json-smart-2.3.jar:/home/user/Storm/storm/lib/guava-27.0.1-jre.jar:/home/user/Storm/storm/lib/failureaccess-1.0.1.jar:/home/user/Storm/storm/lib/jackson-core-2.10.0.jar:/home/user/Storm/storm/lib/jcip-annotations-1.0-1.jar:/home/user/Storm/storm/lib/commons-logging-1.2.jar:/home/user/Storm/storm/lib/carbonite-1.5.0.jar:/home/user/Storm/storm/lib/asm-5.0.3.jar:/home/user/Storm/storm/lib/slf4j-api-1.7.36.jar:/home/user/Storm/storm/lib/metrics-jvm-3.2.6.jar:/home/user/Storm/storm/lib/jakarta.activation-api-1.2.1.jar:/home/user/Storm/storm/lib/reflectasm-1.10.1.jar:/home/user/Storm/storm/lib/zookeeper-jute-3.5.9.jar:/home/user/Storm/storm/lib/snakeyaml-1.26.jar:/home/user/Storm/storm/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/user/Storm/storm/lib/log4j-core-2.17.1.jar:/home/user/Storm/storm/lib/commons-lang-2.6.jar:/home/user/Storm/storm/lib/storm-server-2.4.0.jar:/home/user/Storm/storm/lib/commons-cli-1.4.jar:/home/user/Storm/storm/lib/jetty-io-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/joda-time-2.3.jar:/home/user/Storm/storm/lib/jakarta.activation-1.2.1.jar:/home/user/Storm/storm/extlib/*:/home/user/Storm/storm/extlib-daemon/*:/home/user/Storm/storm/conf
2023-03-28 10:42:36.665 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64
2023-03-28 10:42:36.665 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.io.tmpdir=/tmp
2023-03-28 10:42:36.665 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.compiler=<NA>
2023-03-28 10:42:36.665 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.name=Linux
2023-03-28 10:42:36.665 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.arch=amd64
2023-03-28 10:42:36.665 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.version=5.19.0-35-generic
2023-03-28 10:42:36.666 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.name=user
2023-03-28 10:42:36.666 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.home=/home/user
2023-03-28 10:42:36.666 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.dir=/home/user/Storm/storm
2023-03-28 10:42:36.666 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.free=39MB
2023-03-28 10:42:36.666 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.max=1024MB
2023-03-28 10:42:36.666 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.total=64MB
2023-03-28 10:42:36.667 o.a.s.s.o.a.c.u.Compatibility main [INFO] Using emulated InjectSessionExpiration
2023-03-28 10:42:36.696 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-03-28 10:42:36.697 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-03-28 10:42:36.701 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@3e598df9
2023-03-28 10:42:36.704 o.a.s.s.o.a.z.c.X509Util main [INFO] Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2023-03-28 10:42:36.709 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-03-28 10:42:36.715 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-03-28 10:42:36.726 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:36.734 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-03-28 10:42:36.743 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:37.864 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:37.868 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:38.997 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:38.999 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:40.105 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:40.107 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:41.226 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:41.228 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:42.341 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:42.344 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:43.454 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:43.457 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:44.560 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:44.561 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:45.675 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:45.677 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:46.795 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:46.797 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:47.944 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:47.946 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:49.074 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:49.076 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:50.178 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:50.179 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:51.280 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:51.281 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:52.392 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:52.396 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:53.502 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:53.503 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:54.608 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:54.609 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:55.710 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:55.711 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:56.814 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:56.816 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:56.864 o.a.s.s.o.a.c.f.s.ConnectionStateManager Curator-Framework-0 [INFO] State change: SUSPENDED
2023-03-28 10:42:56.866 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [ERROR] Background operation retry gave up
org.apache.storm.shade.org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss
	at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:102) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.checkBackgroundRetry(CuratorFrameworkImpl.java:862) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:990) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:943) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:66) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:346) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-03-28 10:42:56.918 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [ERROR] Background retry gave up
org.apache.storm.shade.org.apache.curator.CuratorConnectionLossException: KeeperErrorCode = ConnectionLoss
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.performBackgroundOperation(CuratorFrameworkImpl.java:972) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.backgroundOperationsLoop(CuratorFrameworkImpl.java:943) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl.access$300(CuratorFrameworkImpl.java:66) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.CuratorFrameworkImpl$4.call(CuratorFrameworkImpl.java:346) [storm-shaded-deps-2.4.0.jar:2.4.0]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2023-03-28 10:42:57.928 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-03-28 10:42:57.930 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket error occurred: localhost/127.0.0.1:2181: Connection refused
2023-03-28 10:42:58.033 o.a.s.u.Utils main [ERROR] Received error in thread main.. terminating server...
java.lang.Error: java.lang.RuntimeException: org.apache.storm.shade.org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /storm
	at org.apache.storm.utils.Utils.handleUncaughtException(Utils.java:663) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.utils.Utils.handleUncaughtException(Utils.java:667) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.utils.Utils.lambda$createDefaultUncaughtExceptionHandler$2(Utils.java:1047) ~[storm-client-2.4.0.jar:2.4.0]
	at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1055) [?:?]
	at java.lang.ThreadGroup.uncaughtException(ThreadGroup.java:1050) [?:?]
	at java.lang.Thread.dispatchUncaughtException(Thread.java:1997) [?:?]
Caused by: java.lang.RuntimeException: org.apache.storm.shade.org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /storm
	at org.apache.storm.utils.Utils.wrapInRuntime(Utils.java:493) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:147) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ZKStateStorage.<init>(ZKStateStorage.java:65) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ZKStateStorageFactory.mkStore(ZKStateStorageFactory.java:30) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ClusterUtils.mkStateStorageImpl(ClusterUtils.java:318) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ClusterUtils.mkStormClusterStateImpl(ClusterUtils.java:301) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ClusterUtils.mkStormClusterState(ClusterUtils.java:286) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.makeStormClusterState(Nimbus.java:1581) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.<init>(Nimbus.java:562) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.<init>(Nimbus.java:479) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.<init>(Nimbus.java:473) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.launchServer(Nimbus.java:1535) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.launch(Nimbus.java:1560) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.main(Nimbus.java:1565) ~[storm-server-2.4.0.jar:2.4.0]
Caused by: org.apache.storm.shade.org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /storm
	at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:102) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.zookeeper.KeeperException.create(KeeperException.java:54) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:2021) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl$3.call(ExistsBuilderImpl.java:268) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl$3.call(ExistsBuilderImpl.java:257) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.connection.StandardConnectionHandlingPolicy.callWithRetry(StandardConnectionHandlingPolicy.java:67) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:81) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl.pathInForegroundStandard(ExistsBuilderImpl.java:254) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl.pathInForeground(ExistsBuilderImpl.java:247) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl.forPath(ExistsBuilderImpl.java:206) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.shade.org.apache.curator.framework.imps.ExistsBuilderImpl.forPath(ExistsBuilderImpl.java:35) ~[storm-shaded-deps-2.4.0.jar:2.4.0]
	at org.apache.storm.zookeeper.ClientZookeeper.existsNode(ClientZookeeper.java:144) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.zookeeper.ClientZookeeper.mkdirsImpl(ClientZookeeper.java:288) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.zookeeper.ClientZookeeper.mkdirs(ClientZookeeper.java:70) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ZKStateStorage.<init>(ZKStateStorage.java:65) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ZKStateStorageFactory.mkStore(ZKStateStorageFactory.java:30) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ClusterUtils.mkStateStorageImpl(ClusterUtils.java:318) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ClusterUtils.mkStormClusterStateImpl(ClusterUtils.java:301) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.cluster.ClusterUtils.mkStormClusterState(ClusterUtils.java:286) ~[storm-client-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.makeStormClusterState(Nimbus.java:1581) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.<init>(Nimbus.java:562) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.<init>(Nimbus.java:479) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.<init>(Nimbus.java:473) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.launchServer(Nimbus.java:1535) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.launch(Nimbus.java:1560) ~[storm-server-2.4.0.jar:2.4.0]
	at org.apache.storm.daemon.nimbus.Nimbus.main(Nimbus.java:1565) ~[storm-server-2.4.0.jar:2.4.0]
2023-04-11 09:48:06.970 o.a.s.v.ConfigValidation main [INFO] Will use [class org.apache.storm.DaemonConfig, class org.apache.storm.Config] for validation
2023-04-11 09:48:07.136 o.a.s.z.AclEnforcement main [INFO] SECURITY IS DISABLED NO FURTHER CHECKS...
2023-04-11 09:48:07.307 o.a.s.m.r.RocksDbStore main [INFO] Opening RocksDB from /home/user/Storm/storm/storm_rocks
2023-04-11 09:48:07.327 o.a.s.n.NimbusInfo main [INFO] Nimbus figures out its name to Ubuntu.myguest.virtualbox.org
2023-04-11 09:48:07.477 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT
2023-04-11 09:48:07.478 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:host.name=Ubuntu.myguest.virtualbox.org
2023-04-11 09:48:07.478 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.version=11.0.18
2023-04-11 09:48:07.478 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.vendor=Ubuntu
2023-04-11 09:48:07.478 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64
2023-04-11 09:48:07.478 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.class.path=/home/user/Storm/storm/*:/home/user/Storm/storm/lib/nimbus-jose-jwt-4.41.1.jar:/home/user/Storm/storm/lib/netty-resolver-4.1.30.Final.jar:/home/user/Storm/storm/lib/commons-codec-1.11.jar:/home/user/Storm/storm/lib/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/Storm/storm/lib/jackson-databind-2.10.0.jar:/home/user/Storm/storm/lib/jakarta.xml.bind-api-2.3.2.jar:/home/user/Storm/storm/lib/netty-codec-4.1.30.Final.jar:/home/user/Storm/storm/lib/kryo-3.0.3.jar:/home/user/Storm/storm/lib/json-simple-1.1.jar:/home/user/Storm/storm/lib/jetty-http-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/zookeeper-3.5.9.jar:/home/user/Storm/storm/lib/log4j-over-slf4j-1.7.36.jar:/home/user/Storm/storm/lib/jetty-server-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/chill-java-0.8.0.jar:/home/user/Storm/storm/lib/commons-io-2.6.jar:/home/user/Storm/storm/lib/jetty-security-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/checker-qual-2.5.2.jar:/home/user/Storm/storm/lib/error_prone_annotations-2.2.0.jar:/home/user/Storm/storm/lib/storm-client-2.4.0.jar:/home/user/Storm/storm/lib/netty-handler-4.1.30.Final.jar:/home/user/Storm/storm/lib/curator-client-4.3.0.jar:/home/user/Storm/storm/lib/metrics-graphite-3.2.6.jar:/home/user/Storm/storm/lib/commons-collections-3.2.2.jar:/home/user/Storm/storm/lib/kryo-shaded-3.0.3.jar:/home/user/Storm/storm/lib/netty-common-4.1.30.Final.jar:/home/user/Storm/storm/lib/hadoop-auth-2.8.5.jar:/home/user/Storm/storm/lib/storm-clojure-2.4.0.jar:/home/user/Storm/storm/lib/minlog-1.3.0.jar:/home/user/Storm/storm/lib/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/Storm/storm/lib/core.specs.alpha-0.2.44.jar:/home/user/Storm/storm/lib/clojure-1.10.0.jar:/home/user/Storm/storm/lib/jetty-servlets-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/commons-compress-1.18.jar:/home/user/Storm/storm/lib/log4j-api-2.17.1.jar:/home/user/Storm/storm/lib/storm-shaded-deps-2.4.0.jar:/home/user/Storm/storm/lib/audience-annotations-0.5.0.jar:/home/user/Storm/storm/lib/commons-exec-1.3.jar:/home/user/Storm/storm/lib/javax.servlet-api-3.1.0.jar:/home/user/Storm/storm/lib/javax.annotation-api-1.3.2.jar:/home/user/Storm/storm/lib/tools.logging-0.2.3.jar:/home/user/Storm/storm/lib/objenesis-2.1.jar:/home/user/Storm/storm/lib/rocksdbjni-5.18.4.jar:/home/user/Storm/storm/lib/log4j-slf4j-impl-2.17.1.jar:/home/user/Storm/storm/lib/netty-transport-4.1.30.Final.jar:/home/user/Storm/storm/lib/jackson-annotations-2.10.0.jar:/home/user/Storm/storm/lib/httpcore-4.4.10.jar:/home/user/Storm/storm/lib/httpclient-4.5.6.jar:/home/user/Storm/storm/lib/jetty-util-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/spec.alpha-0.2.176.jar:/home/user/Storm/storm/lib/animal-sniffer-annotations-1.17.jar:/home/user/Storm/storm/lib/j2objc-annotations-1.1.jar:/home/user/Storm/storm/lib/jetty-continuation-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/storm-core-2.4.0.jar:/home/user/Storm/storm/lib/accessors-smart-1.2.jar:/home/user/Storm/storm/lib/jsr305-3.0.2.jar:/home/user/Storm/storm/lib/commons-fileupload-1.3.3.jar:/home/user/Storm/storm/lib/jackson-dataformat-smile-2.10.0.jar:/home/user/Storm/storm/lib/netty-buffer-4.1.30.Final.jar:/home/user/Storm/storm/lib/jline-0.9.94.jar:/home/user/Storm/storm/lib/curator-framework-4.3.0.jar:/home/user/Storm/storm/lib/metrics-core-3.2.6.jar:/home/user/Storm/storm/lib/jetty-servlet-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/json-smart-2.3.jar:/home/user/Storm/storm/lib/guava-27.0.1-jre.jar:/home/user/Storm/storm/lib/failureaccess-1.0.1.jar:/home/user/Storm/storm/lib/jackson-core-2.10.0.jar:/home/user/Storm/storm/lib/jcip-annotations-1.0-1.jar:/home/user/Storm/storm/lib/commons-logging-1.2.jar:/home/user/Storm/storm/lib/carbonite-1.5.0.jar:/home/user/Storm/storm/lib/asm-5.0.3.jar:/home/user/Storm/storm/lib/slf4j-api-1.7.36.jar:/home/user/Storm/storm/lib/metrics-jvm-3.2.6.jar:/home/user/Storm/storm/lib/jakarta.activation-api-1.2.1.jar:/home/user/Storm/storm/lib/reflectasm-1.10.1.jar:/home/user/Storm/storm/lib/zookeeper-jute-3.5.9.jar:/home/user/Storm/storm/lib/snakeyaml-1.26.jar:/home/user/Storm/storm/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/user/Storm/storm/lib/log4j-core-2.17.1.jar:/home/user/Storm/storm/lib/commons-lang-2.6.jar:/home/user/Storm/storm/lib/storm-server-2.4.0.jar:/home/user/Storm/storm/lib/commons-cli-1.4.jar:/home/user/Storm/storm/lib/jetty-io-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/joda-time-2.3.jar:/home/user/Storm/storm/lib/jakarta.activation-1.2.1.jar:/home/user/Storm/storm/extlib/*:/home/user/Storm/storm/extlib-daemon/*:/home/user/Storm/storm/conf
2023-04-11 09:48:07.480 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64
2023-04-11 09:48:07.480 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.io.tmpdir=/tmp
2023-04-11 09:48:07.480 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.compiler=<NA>
2023-04-11 09:48:07.480 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.name=Linux
2023-04-11 09:48:07.480 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.arch=amd64
2023-04-11 09:48:07.481 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.version=5.19.0-38-generic
2023-04-11 09:48:07.481 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.name=user
2023-04-11 09:48:07.481 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.home=/home/user
2023-04-11 09:48:07.481 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.dir=/home/user/Storm/storm/bin
2023-04-11 09:48:07.481 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.free=30MB
2023-04-11 09:48:07.481 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.max=1024MB
2023-04-11 09:48:07.481 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.total=64MB
2023-04-11 09:48:07.483 o.a.s.s.o.a.c.u.Compatibility main [INFO] Using emulated InjectSessionExpiration
2023-04-11 09:48:07.557 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 09:48:07.557 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 09:48:07.565 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@3e598df9
2023-04-11 09:48:07.573 o.a.s.s.o.a.z.c.X509Util main [INFO] Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2023-04-11 09:48:07.580 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 09:48:07.590 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 09:48:07.604 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 09:48:07.604 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 09:48:07.617 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:44214, server: localhost/127.0.0.1:2181
2023-04-11 09:48:07.657 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa010000, negotiated timeout = 20000
2023-04-11 09:48:07.663 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 09:48:07.716 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:07.718 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:07.772 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 09:48:07.900 o.a.s.s.o.a.z.ZooKeeper main [INFO] Session: 0x1000011fa010000 closed
2023-04-11 09:48:07.900 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa010000
2023-04-11 09:48:07.905 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 09:48:07.906 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 09:48:07.907 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@7c211fd0
2023-04-11 09:48:07.908 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 09:48:07.908 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 09:48:07.911 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 09:48:07.911 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 09:48:07.915 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:44220, server: localhost/127.0.0.1:2181
2023-04-11 09:48:07.919 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 09:48:07.920 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 09:48:07.921 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@67ec8477
2023-04-11 09:48:07.923 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa010001, negotiated timeout = 20000
2023-04-11 09:48:07.925 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 09:48:07.926 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 09:48:07.927 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 09:48:07.940 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 09:48:07.943 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 09:48:07.944 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:44234, server: localhost/127.0.0.1:2181
2023-04-11 09:48:07.946 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:07.948 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:07.950 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa010002, negotiated timeout = 20000
2023-04-11 09:48:07.950 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 09:48:07.959 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:07.962 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:08.044 o.a.s.d.n.Nimbus main [INFO] Using default scheduler
2023-04-11 09:48:08.054 o.a.s.s.b.BlacklistScheduler main [INFO] Preparing black list scheduler
2023-04-11 09:48:08.062 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 09:48:08.062 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 09:48:08.063 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@189b5fb1
2023-04-11 09:48:08.064 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 09:48:08.064 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 09:48:08.067 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 09:48:08.067 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:44236, server: localhost/127.0.0.1:2181
2023-04-11 09:48:08.069 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 09:48:08.073 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa010003, negotiated timeout = 20000
2023-04-11 09:48:08.074 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 09:48:08.086 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:08.088 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:08.105 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 09:48:08.106 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@13a37e2a
2023-04-11 09:48:08.107 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 09:48:08.108 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 09:48:08.109 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 09:48:08.111 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 09:48:08.112 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:44242, server: localhost/127.0.0.1:2181
2023-04-11 09:48:08.114 o.a.s.b.FileBlobStoreImpl main [INFO] Creating new blob store based in /home/user/Storm/storm//home/user/Storm/Data/Storm/blobs
2023-04-11 09:48:08.117 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa010004, negotiated timeout = 20000
2023-04-11 09:48:08.118 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 09:48:08.130 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:08.131 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:08.198 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 09:48:08.198 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 09:48:08.207 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@2ab2710
2023-04-11 09:48:08.207 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 09:48:08.208 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 09:48:08.209 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 09:48:08.210 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 09:48:08.212 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:44248, server: localhost/127.0.0.1:2181
2023-04-11 09:48:08.218 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa010005, negotiated timeout = 20000
2023-04-11 09:48:08.218 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 09:48:08.227 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:08.227 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 09:48:08.227 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:08.334 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa010005
2023-04-11 09:48:08.334 o.a.s.s.o.a.z.ZooKeeper main [INFO] Session: 0x1000011fa010005 closed
2023-04-11 09:48:08.336 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 09:48:08.336 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 09:48:08.340 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@1f193686
2023-04-11 09:48:08.341 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 09:48:08.341 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 09:48:08.342 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 09:48:08.346 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 09:48:08.346 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:44250, server: localhost/127.0.0.1:2181
2023-04-11 09:48:08.348 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 09:48:08.348 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 09:48:08.349 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@1d25c1c
2023-04-11 09:48:08.349 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 09:48:08.350 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa010006, negotiated timeout = 20000
2023-04-11 09:48:08.349 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 09:48:08.351 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 09:48:08.355 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 09:48:08.358 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 09:48:08.359 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:44262, server: localhost/127.0.0.1:2181
2023-04-11 09:48:08.362 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa010007, negotiated timeout = 20000
2023-04-11 09:48:08.363 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 09:48:08.370 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:08.370 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:08.371 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:08.372 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 09:48:08.392 o.a.s.n.NimbusInfo main [INFO] Nimbus figures out its name to Ubuntu.myguest.virtualbox.org
2023-04-11 09:48:08.432 o.a.s.d.n.Nimbus main [INFO] Starting Nimbus with conf {storm.messaging.netty.min_wait_ms=100, topology.backpressure.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, storm.resource.isolation.plugin=org.apache.storm.container.cgroup.CgroupManager, storm.zookeeper.auth.user=null, storm.messaging.netty.buffer_size=5242880, storm.exhibitor.port=8080, topology.bolt.wait.progressive.level1.count=1, pacemaker.auth.method=NONE, storm.oci.cgroup.root=/sys/fs/cgroup, ui.filter=null, worker.profiler.enabled=false, executor.metrics.frequency.secs=60, supervisor.thrift.threads=16, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, supervisor.supervisors.commands=[], supervisor.queue.size=128, logviewer.cleanup.age.mins=10080, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, storm.cgroup.memory.enforcement.enable=false, drpc.port=3772, supervisor.localizer.update.blob.interval.secs=30, topology.max.spout.pending=null, topology.transfer.buffer.size=1000, storm.oci.nscd.dir=/var/run/nscd, nimbus.worker.heartbeats.recovery.strategy.class=org.apache.storm.nimbus.TimeOutWorkerHeartbeatsRecoveryStrategy, worker.metrics={CGroupMemory=org.apache.storm.metrics2.cgroup.CGroupMemoryUsage, CGroupMemoryLimit=org.apache.storm.metrics2.cgroup.CGroupMemoryLimit, CGroupCpu=org.apache.storm.metrics2.cgroup.CGroupCpu, CGroupCpuGuarantee=org.apache.storm.metrics2.cgroup.CGroupCpuGuarantee, CGroupCpuGuaranteeByCfsQuota=org.apache.storm.metrics2.cgroup.CGroupCpuGuaranteeByCfsQuota, CGroupCpuStat=org.apache.storm.metrics2.cgroup.CGroupCpuStat}, logviewer.port=8000, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, topology.component.cpu.pcore.percent=10.0, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], worker.max.timeout.secs=600, blacklist.scheduler.resume.time.secs=1800, drpc.childopts=-Xmx768m, nimbus.task.launch.secs=120, logviewer.childopts=-Xmx128m, topology.ras.acker.executors.per.worker=1, storm.supervisor.hard.memory.limit.overage.mb=2024, storm.zookeeper.servers=[localhost], storm.messaging.transport=org.apache.storm.messaging.netty.Context, storm.messaging.netty.authentication=false, topology.localityaware.higher.bound=0.8, storm.cgroup.memory.limit.tolerance.margin.mb=0.0, storm.cgroup.hierarchy.name=storm, blacklist.scheduler.assume.supervisor.bad.based.on.bad.slot=true, storm.metricprocessor.class=org.apache.storm.metricstore.NimbusMetricProcessor, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, nimbus.assignments.service.threads=10, worker.heap.memory.mb=768, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, supervisor.slots.ports=[6700, 6701, 6702, 6703], topology.stats.sample.rate=0.05, storm.local.dir=/home/user/Storm/Data/Storm, topology.backpressure.wait.park.microsec=100, topology.ras.constraint.max.state.search=10000, storm.oci.cgroup.parent=/storm, topology.testing.always.try.serialize=false, nimbus.assignments.service.thread.queue.size=100, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64, nimbus.local.assignments.backend.class=org.apache.storm.assignments.InMemoryAssignmentBackend, worker.gc.childopts=, storm.group.mapping.service.cache.duration.secs=120, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, drpc.request.timeout.secs=600, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, topology.state.synchronization.timeout.secs=60, topology.bolt.wait.progressive.level2.count=1000, topology.worker.shared.thread.pool.size=4, topology.executor.receive.buffer.size=32768, pacemaker.servers=[], supervisor.monitor.frequency.secs=3, storm.nimbus.retry.times=5, topology.transfer.batch.size=1, transactional.zookeeper.port=null, storm.auth.simple-white-list.users=[], topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, storm.zookeeper.port=2181, storm.zookeeper.retry.intervalceiling.millis=30000, storm.cluster.state.store=org.apache.storm.cluster.ZKStateStorageFactory, nimbus.thrift.port=6627, blacklist.scheduler.tolerance.count=3, nimbus.thrift.threads=64, supervisor.supervisors=[], nimbus.seeds=[localhost], storm.cluster.metrics.consumer.publish.interval.secs=60, logviewer.filter.params=null, topology.min.replication.count=1, nimbus.blobstore.expiration.secs=600, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, storm.nimbus.retry.interval.millis=2000, topology.max.task.parallelism=null, topology.backpressure.wait.progressive.level2.count=1000, drpc.https.keystore.password=*****, resource.aware.scheduler.constraint.max.state.search=100000, supervisor.heartbeat.frequency.secs=5, nimbus.credential.renewers.freq.secs=600, storm.supervisor.medium.memory.grace.period.ms=30000, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, storm.cgroup.hierarchy.dir=/cgroup/storm_resources, storm.zookeeper.auth.password=null, ui.port=8080, drpc.authorizer.acl.strict=false, topology.message.timeout.secs=30, topology.error.throttle.interval.secs=10, topology.backpressure.check.millis=50, drpc.https.keystore.type=JKS, supervisor.memory.capacity.mb=4096.0, storm.metricstore.class=org.apache.storm.metricstore.rocksdb.RocksDbStore, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, topology.builtin.metrics.bucket.size.secs=60, topology.spout.wait.park.microsec=100, storm.local.mode.zmq=false, pacemaker.client.max.threads=2, ui.header.buffer.bytes=4096, topology.shellbolt.max.pending=100, topology.serialized.message.size.metrics=false, drpc.max_buffer_size=1048576, drpc.disable.http.binding=true, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, nimbus.supervisor.timeout.secs=60, storm.supervisor.cgroup.rootdir=storm, topology.worker.max.heap.size.mb=768.0, storm.zookeeper.root=/storm, topology.disable.loadaware.messaging=false, topology.ras.one.executor.per.worker=false, storm.supervisor.hard.memory.limit.multiplier=2.0, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, worker.heartbeat.frequency.secs=1, storm.messaging.netty.max_wait_ms=1000, topology.backpressure.wait.progressive.level1.count=1, topology.max.error.report.per.interval=5, nimbus.thrift.max_buffer_size=1048576, storm.metricstore.rocksdb.location=storm_rocks, storm.supervisor.low.memory.threshold.mb=1024, pacemaker.max.threads=50, ui.pagination=20, ui.disable.http.binding=true, supervisor.blobstore.download.max_retries=3, topology.enable.message.timeouts=true, logviewer.disable.http.binding=true, storm.messaging.netty.transfer.batch.size=262144, topology.spout.wait.progressive.level2.count=0, blacklist.scheduler.strategy=org.apache.storm.scheduler.blacklist.strategies.DefaultBlacklistStrategy, storm.metricstore.rocksdb.retention_hours=240, supervisor.run.worker.as.user=false, storm.messaging.netty.client_worker_threads=1, topology.tasks=null, supervisor.thrift.socket.timeout.ms=5000, storm.group.mapping.service.params=null, drpc.http.port=3774, transactional.zookeeper.root=/transactional, supervisor.blobstore.download.thread.count=5, logviewer.filter=null, pacemaker.kerberos.users=[], topology.spout.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, storm.blobstore.inputstream.buffer.size.bytes=65536, supervisor.worker.heartbeats.max.timeout.secs=600, supervisor.worker.timeout.secs=30, topology.worker.receiver.thread.count=1, logviewer.max.sum.worker.logs.size.mb=4096, topology.executor.overflow.limit=0, topology.batch.flush.interval.millis=1, nimbus.file.copy.expiration.secs=600, pacemaker.port=6699, topology.worker.logwriter.childopts=-Xmx64m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, nimbus.topology.blobstore.deletion.delay.ms=300000, storm.blobstore.acl.validation.enabled=false, ui.filter.params=null, topology.workers=1, blacklist.scheduler.tolerance.time.secs=300, storm.supervisor.medium.memory.threshold.mb=1536, topology.environment=null, drpc.invocations.port=3773, storm.metricstore.rocksdb.create_if_missing=true, nimbus.cleanup.inbox.freq.secs=600, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.fall.back.on.java.serialization=false, storm.nimbus.retry.intervalceiling.millis=60000, storm.nimbus.zookeeper.acls.fixup=true, logviewer.appender.name=A1, ui.users=null, pacemaker.childopts=-Xmx1024m, storm.messaging.netty.server_worker_threads=1, scheduler.display.resource=false, ui.actions.enabled=true, storm.thrift.socket.timeout.ms=600000, storm.topology.classpath.beginning.enabled=false, storm.zookeeper.connection.timeout=15000, topology.tick.tuple.freq.secs=null, nimbus.inbox.jar.expiration.secs=3600, topology.debug=false, storm.zookeeper.retry.interval=1000, storm.messaging.netty.buffer.high.watermark=16777216, storm.blobstore.dependency.jar.upload.chunk.size.bytes=1048576, worker.log.level.reset.poll.secs=30, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.zookeeper.retry.times=5, nimbus.code.sync.freq.secs=120, topology.component.resources.offheap.memory.mb=0.0, topology.spout.wait.progressive.level1.count=0, topology.state.checkpoint.interval.ms=1000, topology.priority=29, supervisor.localizer.cleanup.interval.ms=30000, nimbus.host=localhost, storm.health.check.dir=healthchecks, supervisor.cpu.capacity=400.0, topology.backpressure.wait.progressive.level3.sleep.millis=1, storm.cgroup.resources=[cpu, memory], storm.worker.min.cpu.pcore.percent=0.0, topology.classpath=null, storm.nimbus.zookeeper.acls.check=true, num.stat.buckets=20, topology.spout.wait.progressive.level3.sleep.millis=1, supervisor.localizer.cache.target.size.mb=10240, topology.worker.childopts=null, drpc.https.port=-1, topology.bolt.wait.park.microsec=100, topology.max.replication.wait.time.sec=60, storm.cgroup.cgexec.cmd=/bin/cgexec, topology.acker.executors=null, topology.bolt.wait.progressive.level3.sleep.millis=1, supervisor.worker.start.timeout.secs=120, supervisor.worker.shutdown.sleep.secs=3, logviewer.max.per.worker.logs.size.mb=2048, topology.trident.batch.emit.interval.millis=500, task.heartbeat.frequency.secs=3, supervisor.enable=true, supervisor.thrift.max_buffer_size=1048576, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.producer.batch.size=1, drpc.worker.threads=64, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, blacklist.scheduler.reporter=org.apache.storm.scheduler.blacklist.reporters.LogReporter, storm.messaging.netty.socket.backlog=500, storm.cgroup.inherit.cpuset.configs=false, nimbus.queue.size=100000, drpc.queue.size=128, ui.disable.spout.lag.monitoring=true, topology.eventlogger.executors=0, pacemaker.base.threads=10, nimbus.childopts=-Xmx1024m, topology.spout.recvq.skips=3, storm.resource.isolation.plugin.enable=false, nimbus.monitor.freq.secs=10, storm.supervisor.memory.limit.tolerance.margin.mb=128.0, storm.disable.symlinks=false, topology.localityaware.lower.bound=0.2, transactional.zookeeper.servers=null, nimbus.task.timeout.secs=30, logs.users=null, pacemaker.thrift.message.size.max=10485760, topology.ras.one.component.per.worker=false, ui.host=0.0.0.0, supervisor.thrift.port=6628, topology.bolt.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, pacemaker.thread.timeout=10, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.skip.missing.kryo.registrations=false, drpc.invocations.threads=64, storm.zookeeper.session.timeout=20000, storm.metricstore.rocksdb.metadata_string_cache_capacity=4000, storm.workers.artifacts.dir=workers-artifacts, topology.component.resources.onheap.memory.mb=128.0, storm.log4j2.conf.dir=log4j2, storm.cluster.mode=distributed, ui.childopts=-Xmx768m, task.refresh.poll.secs=10, supervisor.childopts=-Xmx256m, task.credentials.poll.secs=30, storm.health.check.timeout.ms=5000, storm.blobstore.replication.factor=3, worker.profiler.command=flight.bash, storm.messaging.netty.buffer.low.watermark=8388608}
2023-04-11 09:48:08.502 o.a.s.z.LeaderElectorImp main [INFO] Queued up for leader lock.
2023-04-11 09:48:08.560 o.a.s.n.NimbusInfo main-EventThread [INFO] Nimbus figures out its name to Ubuntu.myguest.virtualbox.org
2023-04-11 09:48:08.586 o.a.s.n.LeaderListenerCallback main-EventThread [INFO] Sync remote assignments and id-info to local
2023-04-11 09:48:08.600 o.a.s.d.m.MetricsUtils main [INFO] Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter
2023-04-11 09:48:08.617 o.a.s.d.m.r.JmxPreparableReporter main [INFO] Preparing...
2023-04-11 09:48:08.632 o.a.s.n.LeaderListenerCallback main-EventThread [INFO] active-topology-blobs [] local-topology-blobs [] diff-topology-blobs []
2023-04-11 09:48:08.638 o.a.s.n.LeaderListenerCallback main-EventThread [INFO] active-topology-dependencies [] local-blobs [] diff-topology-dependencies []
2023-04-11 09:48:08.638 o.a.s.n.LeaderListenerCallback main-EventThread [INFO] Accepting leadership, all active topologies and corresponding dependencies found locally.
2023-04-11 09:48:08.638 o.a.s.z.LeaderListenerCallbackFactory main-EventThread [INFO] Ubuntu.myguest.virtualbox.org gained leadership.
2023-04-11 09:48:08.639 o.a.s.m.StormMetricsRegistry main [INFO] Started statistics report plugin...
2023-04-11 09:48:08.640 o.a.s.d.n.Nimbus main [INFO] Starting nimbus server for storm version '2.4.0'
2023-04-11 09:48:09.126 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:48:19.230 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:48:29.301 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:48:39.342 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:48:49.425 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:48:59.505 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:49:09.599 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:49:19.668 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:49:29.781 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:49:39.867 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:49:49.949 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:50:00.028 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:50:10.077 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:50:20.189 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:50:30.276 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:50:40.367 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:50:50.465 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:51:00.499 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:51:10.581 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:51:20.665 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:51:30.749 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:51:40.824 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:51:50.889 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:52:00.974 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:52:11.047 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:52:21.141 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:52:31.224 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:52:41.288 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:52:51.356 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:53:01.430 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:53:11.522 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:53:21.592 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:53:31.672 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:53:41.739 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:53:51.813 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:54:01.891 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:54:11.947 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:54:22.018 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:54:32.081 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:54:42.137 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:54:52.191 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:55:02.244 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:55:12.301 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:55:22.373 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:55:32.446 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:55:42.494 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:55:52.557 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:56:02.626 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:56:12.688 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:56:22.761 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:56:32.825 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:56:42.884 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:56:52.922 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 09:57:02.824 o.a.s.u.Utils ShutdownHook-sleepKill-10s [INFO] Halting after 10 seconds
2023-04-11 09:57:02.839 o.a.s.d.n.Nimbus ShutdownHook-shutdownFunc [INFO] Shutting down master
2023-04-11 09:57:02.842 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 09:57:02.975 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa010001
2023-04-11 09:57:02.975 o.a.s.s.o.a.z.ZooKeeper ShutdownHook-shutdownFunc [INFO] Session: 0x1000011fa010001 closed
2023-04-11 09:57:02.976 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 09:57:03.088 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa010002
2023-04-11 09:57:03.090 o.a.s.s.o.a.z.ZooKeeper ShutdownHook-shutdownFunc [INFO] Session: 0x1000011fa010002 closed
2023-04-11 09:57:03.091 o.a.s.s.b.BlacklistScheduler ShutdownHook-shutdownFunc [INFO] Cleanup black list scheduler
2023-04-11 09:57:03.092 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 09:57:03.212 o.a.s.s.o.a.z.ZooKeeper ShutdownHook-shutdownFunc [INFO] Session: 0x1000011fa010004 closed
2023-04-11 09:57:03.212 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa010004
2023-04-11 09:57:03.215 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 09:57:03.325 o.a.s.s.o.a.z.ZooKeeper ShutdownHook-shutdownFunc [INFO] Session: 0x1000011fa010006 closed
2023-04-11 09:57:03.325 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa010006
2023-04-11 09:57:03.326 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 09:57:03.439 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa010007
2023-04-11 09:57:03.439 o.a.s.s.o.a.z.ZooKeeper ShutdownHook-shutdownFunc [INFO] Session: 0x1000011fa010007 closed
2023-04-11 09:57:03.457 o.a.s.z.LeaderElectorImp ShutdownHook-shutdownFunc [INFO] Removed from leader lock queue.
2023-04-11 09:57:03.463 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 09:57:03.581 o.a.s.s.o.a.z.ZooKeeper ShutdownHook-shutdownFunc [INFO] Session: 0x1000011fa010003 closed
2023-04-11 09:57:03.581 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa010003
2023-04-11 09:57:03.591 o.a.s.d.n.Nimbus ShutdownHook-shutdownFunc [INFO] Shut down master
2023-04-11 10:27:33.882 o.a.s.v.ConfigValidation main [INFO] Will use [class org.apache.storm.DaemonConfig, class org.apache.storm.Config] for validation
2023-04-11 10:27:34.032 o.a.s.z.AclEnforcement main [INFO] SECURITY IS DISABLED NO FURTHER CHECKS...
2023-04-11 10:27:34.134 o.a.s.m.r.RocksDbStore main [INFO] Opening RocksDB from /home/user/Storm/storm/storm_rocks
2023-04-11 10:27:34.160 o.a.s.n.NimbusInfo main [INFO] Nimbus figures out its name to Ubuntu.myguest.virtualbox.org
2023-04-11 10:27:34.255 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT
2023-04-11 10:27:34.255 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:host.name=Ubuntu.myguest.virtualbox.org
2023-04-11 10:27:34.256 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.version=11.0.18
2023-04-11 10:27:34.256 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.vendor=Ubuntu
2023-04-11 10:27:34.256 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64
2023-04-11 10:27:34.257 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.class.path=/home/user/Storm/storm/*:/home/user/Storm/storm/lib/nimbus-jose-jwt-4.41.1.jar:/home/user/Storm/storm/lib/netty-resolver-4.1.30.Final.jar:/home/user/Storm/storm/lib/commons-codec-1.11.jar:/home/user/Storm/storm/lib/netty-transport-native-epoll-4.1.30.Final.jar:/home/user/Storm/storm/lib/jackson-databind-2.10.0.jar:/home/user/Storm/storm/lib/jakarta.xml.bind-api-2.3.2.jar:/home/user/Storm/storm/lib/netty-codec-4.1.30.Final.jar:/home/user/Storm/storm/lib/kryo-3.0.3.jar:/home/user/Storm/storm/lib/json-simple-1.1.jar:/home/user/Storm/storm/lib/jetty-http-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/zookeeper-3.5.9.jar:/home/user/Storm/storm/lib/log4j-over-slf4j-1.7.36.jar:/home/user/Storm/storm/lib/jetty-server-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/chill-java-0.8.0.jar:/home/user/Storm/storm/lib/commons-io-2.6.jar:/home/user/Storm/storm/lib/jetty-security-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/checker-qual-2.5.2.jar:/home/user/Storm/storm/lib/error_prone_annotations-2.2.0.jar:/home/user/Storm/storm/lib/storm-client-2.4.0.jar:/home/user/Storm/storm/lib/netty-handler-4.1.30.Final.jar:/home/user/Storm/storm/lib/curator-client-4.3.0.jar:/home/user/Storm/storm/lib/metrics-graphite-3.2.6.jar:/home/user/Storm/storm/lib/commons-collections-3.2.2.jar:/home/user/Storm/storm/lib/kryo-shaded-3.0.3.jar:/home/user/Storm/storm/lib/netty-common-4.1.30.Final.jar:/home/user/Storm/storm/lib/hadoop-auth-2.8.5.jar:/home/user/Storm/storm/lib/storm-clojure-2.4.0.jar:/home/user/Storm/storm/lib/minlog-1.3.0.jar:/home/user/Storm/storm/lib/netty-transport-native-unix-common-4.1.30.Final.jar:/home/user/Storm/storm/lib/core.specs.alpha-0.2.44.jar:/home/user/Storm/storm/lib/clojure-1.10.0.jar:/home/user/Storm/storm/lib/jetty-servlets-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/commons-compress-1.18.jar:/home/user/Storm/storm/lib/log4j-api-2.17.1.jar:/home/user/Storm/storm/lib/storm-shaded-deps-2.4.0.jar:/home/user/Storm/storm/lib/audience-annotations-0.5.0.jar:/home/user/Storm/storm/lib/commons-exec-1.3.jar:/home/user/Storm/storm/lib/javax.servlet-api-3.1.0.jar:/home/user/Storm/storm/lib/javax.annotation-api-1.3.2.jar:/home/user/Storm/storm/lib/tools.logging-0.2.3.jar:/home/user/Storm/storm/lib/objenesis-2.1.jar:/home/user/Storm/storm/lib/rocksdbjni-5.18.4.jar:/home/user/Storm/storm/lib/log4j-slf4j-impl-2.17.1.jar:/home/user/Storm/storm/lib/netty-transport-4.1.30.Final.jar:/home/user/Storm/storm/lib/jackson-annotations-2.10.0.jar:/home/user/Storm/storm/lib/httpcore-4.4.10.jar:/home/user/Storm/storm/lib/httpclient-4.5.6.jar:/home/user/Storm/storm/lib/jetty-util-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/spec.alpha-0.2.176.jar:/home/user/Storm/storm/lib/animal-sniffer-annotations-1.17.jar:/home/user/Storm/storm/lib/j2objc-annotations-1.1.jar:/home/user/Storm/storm/lib/jetty-continuation-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/storm-core-2.4.0.jar:/home/user/Storm/storm/lib/accessors-smart-1.2.jar:/home/user/Storm/storm/lib/jsr305-3.0.2.jar:/home/user/Storm/storm/lib/commons-fileupload-1.3.3.jar:/home/user/Storm/storm/lib/jackson-dataformat-smile-2.10.0.jar:/home/user/Storm/storm/lib/netty-buffer-4.1.30.Final.jar:/home/user/Storm/storm/lib/jline-0.9.94.jar:/home/user/Storm/storm/lib/curator-framework-4.3.0.jar:/home/user/Storm/storm/lib/metrics-core-3.2.6.jar:/home/user/Storm/storm/lib/jetty-servlet-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/json-smart-2.3.jar:/home/user/Storm/storm/lib/guava-27.0.1-jre.jar:/home/user/Storm/storm/lib/failureaccess-1.0.1.jar:/home/user/Storm/storm/lib/jackson-core-2.10.0.jar:/home/user/Storm/storm/lib/jcip-annotations-1.0-1.jar:/home/user/Storm/storm/lib/commons-logging-1.2.jar:/home/user/Storm/storm/lib/carbonite-1.5.0.jar:/home/user/Storm/storm/lib/asm-5.0.3.jar:/home/user/Storm/storm/lib/slf4j-api-1.7.36.jar:/home/user/Storm/storm/lib/metrics-jvm-3.2.6.jar:/home/user/Storm/storm/lib/jakarta.activation-api-1.2.1.jar:/home/user/Storm/storm/lib/reflectasm-1.10.1.jar:/home/user/Storm/storm/lib/zookeeper-jute-3.5.9.jar:/home/user/Storm/storm/lib/snakeyaml-1.26.jar:/home/user/Storm/storm/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/user/Storm/storm/lib/log4j-core-2.17.1.jar:/home/user/Storm/storm/lib/commons-lang-2.6.jar:/home/user/Storm/storm/lib/storm-server-2.4.0.jar:/home/user/Storm/storm/lib/commons-cli-1.4.jar:/home/user/Storm/storm/lib/jetty-io-9.4.14.v20181114.jar:/home/user/Storm/storm/lib/joda-time-2.3.jar:/home/user/Storm/storm/lib/jakarta.activation-1.2.1.jar:/home/user/Storm/storm/extlib/*:/home/user/Storm/storm/extlib-daemon/*:/home/user/Storm/storm/conf
2023-04-11 10:27:34.258 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64
2023-04-11 10:27:34.258 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.io.tmpdir=/tmp
2023-04-11 10:27:34.258 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.compiler=<NA>
2023-04-11 10:27:34.258 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.name=Linux
2023-04-11 10:27:34.259 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.arch=amd64
2023-04-11 10:27:34.259 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.version=5.19.0-38-generic
2023-04-11 10:27:34.259 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.name=user
2023-04-11 10:27:34.259 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.home=/home/user
2023-04-11 10:27:34.259 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.dir=/home/user/Storm/storm
2023-04-11 10:27:34.259 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.free=44MB
2023-04-11 10:27:34.260 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.max=1024MB
2023-04-11 10:27:34.260 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.total=64MB
2023-04-11 10:27:34.261 o.a.s.s.o.a.c.u.Compatibility main [INFO] Using emulated InjectSessionExpiration
2023-04-11 10:27:34.297 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 10:27:34.298 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 10:27:34.305 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@6813a331
2023-04-11 10:27:34.309 o.a.s.s.o.a.z.c.X509Util main [INFO] Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2023-04-11 10:27:34.316 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 10:27:34.327 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 10:27:34.349 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 10:27:34.367 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 10:27:34.389 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:33414, server: localhost/127.0.0.1:2181
2023-04-11 10:27:34.402 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa01000c, negotiated timeout = 20000
2023-04-11 10:27:34.407 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 10:27:34.425 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.425 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 10:27:34.426 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.537 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa01000c
2023-04-11 10:27:34.537 o.a.s.s.o.a.z.ZooKeeper main [INFO] Session: 0x1000011fa01000c closed
2023-04-11 10:27:34.547 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 10:27:34.548 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 10:27:34.549 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@72ba28ee
2023-04-11 10:27:34.550 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 10:27:34.550 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 10:27:34.554 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 10:27:34.555 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 10:27:34.555 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:33426, server: localhost/127.0.0.1:2181
2023-04-11 10:27:34.559 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa01000d, negotiated timeout = 20000
2023-04-11 10:27:34.560 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 10:27:34.563 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.564 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.566 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 10:27:34.567 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 10:27:34.567 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@c3fa05a
2023-04-11 10:27:34.568 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 10:27:34.569 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 10:27:34.572 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 10:27:34.572 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:33428, server: localhost/127.0.0.1:2181
2023-04-11 10:27:34.575 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 10:27:34.576 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa01000e, negotiated timeout = 20000
2023-04-11 10:27:34.576 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 10:27:34.581 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.582 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.602 o.a.s.d.n.Nimbus main [INFO] Using default scheduler
2023-04-11 10:27:34.605 o.a.s.s.b.BlacklistScheduler main [INFO] Preparing black list scheduler
2023-04-11 10:27:34.611 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 10:27:34.611 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 10:27:34.612 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@6ad6fa53
2023-04-11 10:27:34.613 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 10:27:34.613 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 10:27:34.614 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 10:27:34.614 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 10:27:34.615 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:33444, server: localhost/127.0.0.1:2181
2023-04-11 10:27:34.617 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa01000f, negotiated timeout = 20000
2023-04-11 10:27:34.618 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 10:27:34.621 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.622 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.638 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 10:27:34.639 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@66bfd864
2023-04-11 10:27:34.640 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 10:27:34.640 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 10:27:34.643 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 10:27:34.643 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 10:27:34.643 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:33454, server: localhost/127.0.0.1:2181
2023-04-11 10:27:34.646 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa010010, negotiated timeout = 20000
2023-04-11 10:27:34.647 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 10:27:34.651 o.a.s.b.FileBlobStoreImpl main [INFO] Creating new blob store based in /home/user/Storm/storm//home/user/Storm/Data/Storm/blobs
2023-04-11 10:27:34.652 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.653 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.710 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 10:27:34.711 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 10:27:34.712 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@385ef531
2023-04-11 10:27:34.712 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 10:27:34.712 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 10:27:34.719 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 10:27:34.721 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:33462, server: localhost/127.0.0.1:2181
2023-04-11 10:27:34.723 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa010011, negotiated timeout = 20000
2023-04-11 10:27:34.727 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 10:27:34.727 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 10:27:34.731 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 10:27:34.733 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.733 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.836 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa010011
2023-04-11 10:27:34.836 o.a.s.s.o.a.z.ZooKeeper main [INFO] Session: 0x1000011fa010011 closed
2023-04-11 10:27:34.839 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 10:27:34.839 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 10:27:34.840 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@58112bc4
2023-04-11 10:27:34.841 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 10:27:34.842 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 10:27:34.846 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 10:27:34.846 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 10:27:34.847 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:33470, server: localhost/127.0.0.1:2181
2023-04-11 10:27:34.850 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-04-11 10:27:34.850 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-04-11 10:27:34.851 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=localhost:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@258ee7de
2023-04-11 10:27:34.852 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa010012, negotiated timeout = 20000
2023-04-11 10:27:34.852 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-04-11 10:27:34.852 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 10:27:34.852 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-04-11 10:27:34.855 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-04-11 10:27:34.857 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.857 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
2023-04-11 10:27:34.858 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.858 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Socket connection established, initiating session, client: /127.0.0.1:33476, server: localhost/127.0.0.1:2181
2023-04-11 10:27:34.863 o.a.s.s.o.a.z.ClientCnxn main-SendThread(localhost:2181) [INFO] Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1000011fa010013, negotiated timeout = 20000
2023-04-11 10:27:34.863 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-04-11 10:27:34.868 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.868 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {}
2023-04-11 10:27:34.879 o.a.s.n.NimbusInfo main [INFO] Nimbus figures out its name to Ubuntu.myguest.virtualbox.org
2023-04-11 10:27:34.905 o.a.s.d.n.Nimbus main [INFO] Starting Nimbus with conf {storm.messaging.netty.min_wait_ms=100, topology.backpressure.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, storm.resource.isolation.plugin=org.apache.storm.container.cgroup.CgroupManager, storm.zookeeper.auth.user=null, storm.messaging.netty.buffer_size=5242880, storm.exhibitor.port=8080, topology.bolt.wait.progressive.level1.count=1, pacemaker.auth.method=NONE, storm.oci.cgroup.root=/sys/fs/cgroup, ui.filter=null, worker.profiler.enabled=false, executor.metrics.frequency.secs=60, supervisor.thrift.threads=16, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, supervisor.supervisors.commands=[], supervisor.queue.size=128, logviewer.cleanup.age.mins=10080, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, storm.cgroup.memory.enforcement.enable=false, drpc.port=3772, supervisor.localizer.update.blob.interval.secs=30, topology.max.spout.pending=null, topology.transfer.buffer.size=1000, storm.oci.nscd.dir=/var/run/nscd, nimbus.worker.heartbeats.recovery.strategy.class=org.apache.storm.nimbus.TimeOutWorkerHeartbeatsRecoveryStrategy, worker.metrics={CGroupMemory=org.apache.storm.metrics2.cgroup.CGroupMemoryUsage, CGroupMemoryLimit=org.apache.storm.metrics2.cgroup.CGroupMemoryLimit, CGroupCpu=org.apache.storm.metrics2.cgroup.CGroupCpu, CGroupCpuGuarantee=org.apache.storm.metrics2.cgroup.CGroupCpuGuarantee, CGroupCpuGuaranteeByCfsQuota=org.apache.storm.metrics2.cgroup.CGroupCpuGuaranteeByCfsQuota, CGroupCpuStat=org.apache.storm.metrics2.cgroup.CGroupCpuStat}, logviewer.port=8000, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, topology.component.cpu.pcore.percent=10.0, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], worker.max.timeout.secs=600, blacklist.scheduler.resume.time.secs=1800, drpc.childopts=-Xmx768m, nimbus.task.launch.secs=120, logviewer.childopts=-Xmx128m, topology.ras.acker.executors.per.worker=1, storm.supervisor.hard.memory.limit.overage.mb=2024, storm.zookeeper.servers=[localhost], storm.messaging.transport=org.apache.storm.messaging.netty.Context, storm.messaging.netty.authentication=false, topology.localityaware.higher.bound=0.8, storm.cgroup.memory.limit.tolerance.margin.mb=0.0, storm.cgroup.hierarchy.name=storm, blacklist.scheduler.assume.supervisor.bad.based.on.bad.slot=true, storm.metricprocessor.class=org.apache.storm.metricstore.NimbusMetricProcessor, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, nimbus.assignments.service.threads=10, worker.heap.memory.mb=768, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, supervisor.slots.ports=[6700, 6701, 6702, 6703], topology.stats.sample.rate=0.05, storm.local.dir=/home/user/Storm/Data/Storm, topology.backpressure.wait.park.microsec=100, topology.ras.constraint.max.state.search=10000, storm.oci.cgroup.parent=/storm, topology.testing.always.try.serialize=false, nimbus.assignments.service.thread.queue.size=100, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64, nimbus.local.assignments.backend.class=org.apache.storm.assignments.InMemoryAssignmentBackend, worker.gc.childopts=, storm.group.mapping.service.cache.duration.secs=120, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, drpc.request.timeout.secs=600, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, topology.state.synchronization.timeout.secs=60, topology.bolt.wait.progressive.level2.count=1000, topology.worker.shared.thread.pool.size=4, topology.executor.receive.buffer.size=32768, pacemaker.servers=[], supervisor.monitor.frequency.secs=3, storm.nimbus.retry.times=5, topology.transfer.batch.size=1, transactional.zookeeper.port=null, storm.auth.simple-white-list.users=[], topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, storm.zookeeper.port=2181, storm.zookeeper.retry.intervalceiling.millis=30000, storm.cluster.state.store=org.apache.storm.cluster.ZKStateStorageFactory, nimbus.thrift.port=6627, blacklist.scheduler.tolerance.count=3, nimbus.thrift.threads=64, supervisor.supervisors=[], nimbus.seeds=[localhost], storm.cluster.metrics.consumer.publish.interval.secs=60, logviewer.filter.params=null, topology.min.replication.count=1, nimbus.blobstore.expiration.secs=600, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, storm.nimbus.retry.interval.millis=2000, topology.max.task.parallelism=null, topology.backpressure.wait.progressive.level2.count=1000, drpc.https.keystore.password=*****, resource.aware.scheduler.constraint.max.state.search=100000, supervisor.heartbeat.frequency.secs=5, nimbus.credential.renewers.freq.secs=600, storm.supervisor.medium.memory.grace.period.ms=30000, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, storm.cgroup.hierarchy.dir=/cgroup/storm_resources, storm.zookeeper.auth.password=null, ui.port=8081, drpc.authorizer.acl.strict=false, topology.message.timeout.secs=30, topology.error.throttle.interval.secs=10, topology.backpressure.check.millis=50, drpc.https.keystore.type=JKS, supervisor.memory.capacity.mb=4096.0, storm.metricstore.class=org.apache.storm.metricstore.rocksdb.RocksDbStore, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, topology.builtin.metrics.bucket.size.secs=60, topology.spout.wait.park.microsec=100, storm.local.mode.zmq=false, pacemaker.client.max.threads=2, ui.header.buffer.bytes=4096, topology.shellbolt.max.pending=100, topology.serialized.message.size.metrics=false, drpc.max_buffer_size=1048576, drpc.disable.http.binding=true, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, nimbus.supervisor.timeout.secs=60, storm.supervisor.cgroup.rootdir=storm, topology.worker.max.heap.size.mb=768.0, storm.zookeeper.root=/storm, topology.disable.loadaware.messaging=false, topology.ras.one.executor.per.worker=false, storm.supervisor.hard.memory.limit.multiplier=2.0, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, worker.heartbeat.frequency.secs=1, storm.messaging.netty.max_wait_ms=1000, topology.backpressure.wait.progressive.level1.count=1, topology.max.error.report.per.interval=5, nimbus.thrift.max_buffer_size=1048576, storm.metricstore.rocksdb.location=storm_rocks, storm.supervisor.low.memory.threshold.mb=1024, pacemaker.max.threads=50, ui.pagination=20, ui.disable.http.binding=true, supervisor.blobstore.download.max_retries=3, topology.enable.message.timeouts=true, logviewer.disable.http.binding=true, storm.messaging.netty.transfer.batch.size=262144, topology.spout.wait.progressive.level2.count=0, blacklist.scheduler.strategy=org.apache.storm.scheduler.blacklist.strategies.DefaultBlacklistStrategy, storm.metricstore.rocksdb.retention_hours=240, supervisor.run.worker.as.user=false, storm.messaging.netty.client_worker_threads=1, topology.tasks=null, supervisor.thrift.socket.timeout.ms=5000, storm.group.mapping.service.params=null, drpc.http.port=3774, transactional.zookeeper.root=/transactional, supervisor.blobstore.download.thread.count=5, logviewer.filter=null, pacemaker.kerberos.users=[], topology.spout.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, storm.blobstore.inputstream.buffer.size.bytes=65536, supervisor.worker.heartbeats.max.timeout.secs=600, supervisor.worker.timeout.secs=30, topology.worker.receiver.thread.count=1, logviewer.max.sum.worker.logs.size.mb=4096, topology.executor.overflow.limit=0, topology.batch.flush.interval.millis=1, nimbus.file.copy.expiration.secs=600, pacemaker.port=6699, topology.worker.logwriter.childopts=-Xmx64m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, nimbus.topology.blobstore.deletion.delay.ms=300000, storm.blobstore.acl.validation.enabled=false, ui.filter.params=null, topology.workers=1, blacklist.scheduler.tolerance.time.secs=300, storm.supervisor.medium.memory.threshold.mb=1536, topology.environment=null, drpc.invocations.port=3773, storm.metricstore.rocksdb.create_if_missing=true, nimbus.cleanup.inbox.freq.secs=600, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.fall.back.on.java.serialization=false, storm.nimbus.retry.intervalceiling.millis=60000, storm.nimbus.zookeeper.acls.fixup=true, logviewer.appender.name=A1, ui.users=null, pacemaker.childopts=-Xmx1024m, storm.messaging.netty.server_worker_threads=1, scheduler.display.resource=false, ui.actions.enabled=true, storm.thrift.socket.timeout.ms=600000, storm.topology.classpath.beginning.enabled=false, storm.zookeeper.connection.timeout=15000, topology.tick.tuple.freq.secs=null, nimbus.inbox.jar.expiration.secs=3600, topology.debug=false, storm.zookeeper.retry.interval=1000, storm.messaging.netty.buffer.high.watermark=16777216, storm.blobstore.dependency.jar.upload.chunk.size.bytes=1048576, worker.log.level.reset.poll.secs=30, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.zookeeper.retry.times=5, nimbus.code.sync.freq.secs=120, topology.component.resources.offheap.memory.mb=0.0, topology.spout.wait.progressive.level1.count=0, topology.state.checkpoint.interval.ms=1000, topology.priority=29, supervisor.localizer.cleanup.interval.ms=30000, nimbus.host=localhost, storm.health.check.dir=healthchecks, supervisor.cpu.capacity=400.0, topology.backpressure.wait.progressive.level3.sleep.millis=1, storm.cgroup.resources=[cpu, memory], storm.worker.min.cpu.pcore.percent=0.0, topology.classpath=null, storm.nimbus.zookeeper.acls.check=true, num.stat.buckets=20, topology.spout.wait.progressive.level3.sleep.millis=1, supervisor.localizer.cache.target.size.mb=10240, topology.worker.childopts=null, drpc.https.port=-1, topology.bolt.wait.park.microsec=100, topology.max.replication.wait.time.sec=60, storm.cgroup.cgexec.cmd=/bin/cgexec, topology.acker.executors=null, topology.bolt.wait.progressive.level3.sleep.millis=1, supervisor.worker.start.timeout.secs=120, supervisor.worker.shutdown.sleep.secs=3, logviewer.max.per.worker.logs.size.mb=2048, topology.trident.batch.emit.interval.millis=500, task.heartbeat.frequency.secs=3, supervisor.enable=true, supervisor.thrift.max_buffer_size=1048576, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.producer.batch.size=1, drpc.worker.threads=64, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, blacklist.scheduler.reporter=org.apache.storm.scheduler.blacklist.reporters.LogReporter, storm.messaging.netty.socket.backlog=500, storm.cgroup.inherit.cpuset.configs=false, nimbus.queue.size=100000, drpc.queue.size=128, ui.disable.spout.lag.monitoring=true, topology.eventlogger.executors=0, pacemaker.base.threads=10, nimbus.childopts=-Xmx1024m, topology.spout.recvq.skips=3, storm.resource.isolation.plugin.enable=false, nimbus.monitor.freq.secs=10, storm.supervisor.memory.limit.tolerance.margin.mb=128.0, storm.disable.symlinks=false, topology.localityaware.lower.bound=0.2, transactional.zookeeper.servers=null, nimbus.task.timeout.secs=30, logs.users=null, pacemaker.thrift.message.size.max=10485760, topology.ras.one.component.per.worker=false, ui.host=0.0.0.0, supervisor.thrift.port=6628, topology.bolt.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, pacemaker.thread.timeout=10, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.skip.missing.kryo.registrations=false, drpc.invocations.threads=64, storm.zookeeper.session.timeout=20000, storm.metricstore.rocksdb.metadata_string_cache_capacity=4000, storm.workers.artifacts.dir=workers-artifacts, topology.component.resources.onheap.memory.mb=128.0, storm.log4j2.conf.dir=log4j2, storm.cluster.mode=distributed, ui.childopts=-Xmx768m, task.refresh.poll.secs=10, supervisor.childopts=-Xmx256m, task.credentials.poll.secs=30, storm.health.check.timeout.ms=5000, storm.blobstore.replication.factor=3, worker.profiler.command=flight.bash, storm.messaging.netty.buffer.low.watermark=8388608}
2023-04-11 10:27:34.965 o.a.s.z.LeaderElectorImp main [INFO] Queued up for leader lock.
2023-04-11 10:27:35.024 o.a.s.n.NimbusInfo main-EventThread [INFO] Nimbus figures out its name to Ubuntu.myguest.virtualbox.org
2023-04-11 10:27:35.038 o.a.s.n.LeaderListenerCallback main-EventThread [INFO] Sync remote assignments and id-info to local
2023-04-11 10:27:35.043 o.a.s.d.m.MetricsUtils main [INFO] Using statistics reporter plugin:org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter
2023-04-11 10:27:35.045 o.a.s.d.m.r.JmxPreparableReporter main [INFO] Preparing...
2023-04-11 10:27:35.065 o.a.s.n.LeaderListenerCallback main-EventThread [INFO] active-topology-blobs [] local-topology-blobs [] diff-topology-blobs []
2023-04-11 10:27:35.072 o.a.s.m.StormMetricsRegistry main [INFO] Started statistics report plugin...
2023-04-11 10:27:35.072 o.a.s.n.LeaderListenerCallback main-EventThread [INFO] active-topology-dependencies [] local-blobs [] diff-topology-dependencies []
2023-04-11 10:27:35.072 o.a.s.n.LeaderListenerCallback main-EventThread [INFO] Accepting leadership, all active topologies and corresponding dependencies found locally.
2023-04-11 10:27:35.072 o.a.s.z.LeaderListenerCallbackFactory main-EventThread [INFO] Ubuntu.myguest.virtualbox.org gained leadership.
2023-04-11 10:27:35.073 o.a.s.d.n.Nimbus main [INFO] Starting nimbus server for storm version '2.4.0'
2023-04-11 10:27:35.712 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:27:45.833 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:27:55.916 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:28:05.949 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:28:15.985 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:28:26.041 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:28:36.073 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:28:46.139 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:28:56.209 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:29:06.279 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:29:16.358 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:29:26.420 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:29:36.484 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:29:46.525 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:29:56.576 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:30:06.612 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:30:16.685 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:30:26.756 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:30:36.809 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:30:46.865 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:30:56.935 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:31:06.993 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:31:17.086 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:31:27.159 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:31:37.228 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:31:47.290 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:31:57.384 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:32:07.448 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:32:17.513 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:32:27.576 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:32:37.642 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:32:47.707 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:32:57.782 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:33:07.858 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:33:17.913 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:33:27.982 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:33:38.053 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:33:48.117 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:33:58.191 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:34:08.255 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:34:18.313 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:34:28.363 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:34:38.392 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:34:48.461 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:34:58.517 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:35:08.576 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:35:18.650 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:35:28.701 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:35:38.738 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:35:48.795 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:35:58.850 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:36:08.923 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:36:18.983 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:36:29.050 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:36:39.112 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:36:49.170 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:36:59.238 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:37:09.296 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:37:19.345 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:37:29.397 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:37:39.443 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:37:49.504 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:37:59.571 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:38:09.615 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:38:19.651 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:38:29.674 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:38:39.735 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:38:49.860 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:38:59.908 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:39:09.966 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:39:20.027 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:39:30.073 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:39:40.131 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:39:50.182 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:40:00.255 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:40:10.309 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:40:20.368 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:40:30.436 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:40:40.508 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:40:50.571 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:41:00.627 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:41:10.690 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:41:20.746 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:41:30.804 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:41:40.865 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:41:50.925 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:42:00.974 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:42:11.032 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:42:21.093 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:42:31.162 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:42:41.230 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:42:51.307 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:43:01.355 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:43:11.388 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:43:21.450 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:43:31.533 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:43:41.593 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:43:51.649 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:44:01.716 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:44:11.777 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:44:21.843 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:44:31.909 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:44:41.966 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:44:52.016 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:45:02.074 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:45:12.126 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:45:22.179 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:45:32.238 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:45:42.300 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:45:52.367 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:46:02.426 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:46:12.501 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:46:22.563 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:46:32.612 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:46:42.667 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:46:52.724 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:47:02.779 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:47:12.834 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:47:22.887 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:47:32.943 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:47:43.011 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:47:53.063 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:48:03.128 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:48:13.185 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:48:23.237 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:48:33.292 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:48:43.356 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:48:53.409 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:49:03.468 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:49:13.516 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:49:23.568 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:49:33.615 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:49:43.666 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:49:53.731 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:50:03.781 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:50:13.835 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:50:23.896 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:50:33.945 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:50:43.999 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:50:54.041 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:50:55.903 o.a.s.d.n.Nimbus pool-29-thread-33 [INFO] Uploading file from client to /home/user/Storm/storm//home/user/Storm/Data/Storm/nimbus/inbox/stormjar-919a3992-e321-438b-8b41-04ad7b2694f7.jar
2023-04-11 10:50:55.939 o.a.s.d.n.Nimbus pool-29-thread-37 [INFO] Finished uploading file from client: /home/user/Storm/storm//home/user/Storm/Data/Storm/nimbus/inbox/stormjar-919a3992-e321-438b-8b41-04ad7b2694f7.jar
2023-04-11 10:50:56.032 o.a.s.d.n.Nimbus pool-29-thread-35 [INFO] Received topology submission for WordCount (storm-2.4.0 JDK-11.0.18) with conf {topology.users=[null], topology.acker.executors=null, storm.messaging.netty.authentication=false, storm.zookeeper.superACL=null, topology.workers=3, topology.submitter.principal=, topology.debug=true, topology.name=WordCount, worker.metrics={CGroupMemory=org.apache.storm.metrics2.cgroup.CGroupMemoryUsage, CGroupMemoryLimit=org.apache.storm.metrics2.cgroup.CGroupMemoryLimit, CGroupCpu=org.apache.storm.metrics2.cgroup.CGroupCpu, CGroupCpuGuarantee=org.apache.storm.metrics2.cgroup.CGroupCpuGuarantee, CGroupCpuGuaranteeByCfsQuota=org.apache.storm.metrics2.cgroup.CGroupCpuGuaranteeByCfsQuota, CGroupCpuStat=org.apache.storm.metrics2.cgroup.CGroupCpuStat}, storm.cgroup.hierarchy.dir=/cgroup/storm_resources, topology.kryo.register={}, storm.id=WordCount-1-1681199456, topology.kryo.decorators=[], topology.eventlogger.executors=0, topology.submitter.user=user, topology.max.task.parallelism=null}
2023-04-11 10:50:56.032 o.a.s.d.n.Nimbus pool-29-thread-35 [INFO] uploadedJar /home/user/Storm/storm//home/user/Storm/Data/Storm/nimbus/inbox/stormjar-919a3992-e321-438b-8b41-04ad7b2694f7.jar for WordCount
2023-04-11 10:50:56.049 o.a.s.c.StormClusterStateImpl pool-29-thread-35 [INFO] set-path: /blobstore/WordCount-1-1681199456-stormjar.jar/Ubuntu.myguest.virtualbox.org:6627-1
2023-04-11 10:50:56.081 o.a.s.c.StormClusterStateImpl pool-29-thread-35 [INFO] set-path: /blobstore/WordCount-1-1681199456-stormconf.ser/Ubuntu.myguest.virtualbox.org:6627-1
2023-04-11 10:50:56.096 o.a.s.c.StormClusterStateImpl pool-29-thread-35 [INFO] set-path: /blobstore/WordCount-1-1681199456-stormcode.ser/Ubuntu.myguest.virtualbox.org:6627-1
2023-04-11 10:50:56.109 o.a.s.d.n.Nimbus pool-29-thread-35 [INFO] desired replication count 1 achieved for topology WordCount-1-1681199456, current-replication-count for conf key = 1, current-replication-count for code key = 1, current-replication-count for jar key = 1
2023-04-11 10:50:56.119 o.a.s.d.n.Nimbus pool-29-thread-35 [INFO] Activating WordCount: WordCount-1-1681199456
2023-04-11 10:51:04.084 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:51:04.092 o.a.s.s.EvenScheduler timer [INFO] Available slots: [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6700, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6701, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6702, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6703]
2023-04-11 10:51:04.131 o.a.s.d.n.Nimbus timer [INFO] Assigning WordCount-1-1681199456 to 3 slots
2023-04-11 10:51:04.132 o.a.s.d.n.Nimbus timer [INFO] Assign executors: [[20, 20], [14, 14], [12, 12], [16, 16], [18, 18], [28, 28], [26, 26], [10, 10], [8, 8], [24, 24], [6, 6], [22, 22], [2, 2], [4, 4], [13, 13], [11, 11], [7, 7], [9, 9], [19, 19], [23, 23], [21, 21], [25, 25], [27, 27], [5, 5], [1, 1], [3, 3], [15, 15], [17, 17]]
2023-04-11 10:51:04.140 o.a.s.d.n.Nimbus timer [INFO] Fragmentation after scheduling is: 0.0 MB, 0 PCore CPUs
2023-04-11 10:51:04.141 o.a.s.d.n.Nimbus timer [INFO] Node Id: cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1 Total Mem: 4096.0, Used Mem: 3584.0, Available Mem: 512.0, Total CPU: 400.0, Used CPU: 280.0, Available CPU: 120.0, fragmented: false
2023-04-11 10:51:04.142 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id WordCount-1-1681199456: Assignment(master_code_dir:/home/user/Storm/Data/Storm, node_host:{cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=Ubuntu.myguest.virtualbox.org}, executor_node_port:{[20, 20]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [14, 14]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [12, 12]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [16, 16]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [18, 18]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [28, 28]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [26, 26]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [10, 10]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [8, 8]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [24, 24]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [6, 6]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [22, 22]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [2, 2]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [4, 4]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [13, 13]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [11, 11]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [7, 7]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [9, 9]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [19, 19]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [23, 23]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [21, 21]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [25, 25]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [27, 27]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [5, 5]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [1, 1]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [3, 3]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [15, 15]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [17, 17]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701])}, executor_start_time_secs:{[12, 12]=1681199464, [6, 6]=1681199464, [18, 18]=1681199464, [24, 24]=1681199464, [2, 2]=1681199464, [4, 4]=1681199464, [8, 8]=1681199464, [10, 10]=1681199464, [14, 14]=1681199464, [16, 16]=1681199464, [20, 20]=1681199464, [22, 22]=1681199464, [26, 26]=1681199464, [28, 28]=1681199464, [9, 9]=1681199464, [3, 3]=1681199464, [1, 1]=1681199464, [15, 15]=1681199464, [21, 21]=1681199464, [27, 27]=1681199464, [5, 5]=1681199464, [7, 7]=1681199464, [11, 11]=1681199464, [13, 13]=1681199464, [17, 17]=1681199464, [19, 19]=1681199464, [23, 23]=1681199464, [25, 25]=1681199464}, worker_resources:{NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702])=WorkerResources(mem_on_heap:1152.0, mem_off_heap:0.0, cpu:90.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1152.0, cpu.pcore.percent=90.0, offheap.memory.mb=0.0}, shared_resources:{}), NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701])=WorkerResources(mem_on_heap:1152.0, mem_off_heap:0.0, cpu:90.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1152.0, cpu.pcore.percent=90.0, offheap.memory.mb=0.0}, shared_resources:{}), NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700])=WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1280.0, cpu.pcore.percent=100.0, offheap.memory.mb=0.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:user)
2023-04-11 10:51:05.178 o.a.s.d.n.Nimbus pool-29-thread-62 [INFO] Created download session c7793176-42ac-499f-b1b1-29a502c0781d for WordCount-1-1681199456-stormjar.jar
2023-04-11 10:51:05.195 o.a.s.d.n.Nimbus pool-29-thread-64 [INFO] Created download session 53be577d-2c33-40d6-8fb8-0ac24bc48350 for WordCount-1-1681199456-stormcode.ser
2023-04-11 10:51:05.202 o.a.s.d.n.Nimbus pool-29-thread-63 [INFO] Created download session f95ad478-e284-4d0b-9876-d5eb71d086ae for WordCount-1-1681199456-stormconf.ser
2023-04-11 10:51:14.228 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:51:24.291 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:51:34.381 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:51:44.470 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:51:54.549 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:52:04.592 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:52:14.630 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:52:24.671 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:52:34.724 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:52:44.813 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:52:54.893 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:53:04.971 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[8, 8] not alive
2023-04-11 10:53:04.972 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[16, 16] not alive
2023-04-11 10:53:04.973 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[14, 14] not alive
2023-04-11 10:53:04.974 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[18, 18] not alive
2023-04-11 10:53:04.975 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[20, 20] not alive
2023-04-11 10:53:04.975 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[22, 22] not alive
2023-04-11 10:53:04.976 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[24, 24] not alive
2023-04-11 10:53:04.976 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[26, 26] not alive
2023-04-11 10:53:04.977 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[28, 28] not alive
2023-04-11 10:53:04.978 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[2, 2] not alive
2023-04-11 10:53:04.978 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[4, 4] not alive
2023-04-11 10:53:04.979 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[6, 6] not alive
2023-04-11 10:53:04.980 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[10, 10] not alive
2023-04-11 10:53:04.980 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[12, 12] not alive
2023-04-11 10:53:04.981 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[7, 7] not alive
2023-04-11 10:53:04.982 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[17, 17] not alive
2023-04-11 10:53:04.982 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[13, 13] not alive
2023-04-11 10:53:04.983 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[15, 15] not alive
2023-04-11 10:53:04.984 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[19, 19] not alive
2023-04-11 10:53:04.984 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[21, 21] not alive
2023-04-11 10:53:04.985 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[23, 23] not alive
2023-04-11 10:53:04.985 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[25, 25] not alive
2023-04-11 10:53:04.987 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[27, 27] not alive
2023-04-11 10:53:04.988 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[1, 1] not alive
2023-04-11 10:53:04.989 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[3, 3] not alive
2023-04-11 10:53:04.990 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[5, 5] not alive
2023-04-11 10:53:04.990 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[9, 9] not alive
2023-04-11 10:53:04.991 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[11, 11] not alive
2023-04-11 10:53:05.004 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:53:05.007 o.a.s.s.EvenScheduler timer [INFO] Available slots: [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6703]
2023-04-11 10:53:05.019 o.a.s.d.n.Nimbus timer [INFO] Reassigning WordCount-1-1681199456 to 1 slots
2023-04-11 10:53:05.019 o.a.s.d.n.Nimbus timer [INFO] Reassign executors: [[20, 20], [14, 14], [12, 12], [16, 16], [18, 18], [28, 28], [26, 26], [10, 10], [8, 8], [24, 24], [6, 6], [22, 22], [2, 2], [4, 4], [13, 13], [11, 11], [7, 7], [9, 9], [19, 19], [23, 23], [21, 21], [25, 25], [27, 27], [5, 5], [1, 1], [3, 3], [15, 15], [17, 17]]
2023-04-11 10:53:05.022 o.a.s.d.n.Nimbus timer [INFO] Fragmentation after scheduling is: 0.0 MB, 0 PCore CPUs
2023-04-11 10:53:05.022 o.a.s.d.n.Nimbus timer [INFO] Node Id: cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1 Total Mem: 4096.0, Used Mem: 3584.0, Available Mem: 512.0, Total CPU: 400.0, Used CPU: 280.0, Available CPU: 120.0, fragmented: false
2023-04-11 10:53:05.023 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id WordCount-1-1681199456: Assignment(master_code_dir:/home/user/Storm/Data/Storm, node_host:{cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=Ubuntu.myguest.virtualbox.org}, executor_node_port:{[20, 20]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [14, 14]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [12, 12]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [16, 16]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [18, 18]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [28, 28]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [26, 26]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [10, 10]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [8, 8]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [24, 24]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [6, 6]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [22, 22]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [2, 2]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [4, 4]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [13, 13]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [11, 11]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [7, 7]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [9, 9]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [19, 19]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [23, 23]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [21, 21]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [25, 25]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [27, 27]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [5, 5]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [1, 1]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [3, 3]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [15, 15]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [17, 17]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703])}, executor_start_time_secs:{[12, 12]=1681199585, [6, 6]=1681199585, [18, 18]=1681199585, [24, 24]=1681199585, [26, 26]=1681199585, [28, 28]=1681199585, [20, 20]=1681199585, [22, 22]=1681199585, [2, 2]=1681199585, [4, 4]=1681199585, [8, 8]=1681199585, [10, 10]=1681199585, [14, 14]=1681199585, [16, 16]=1681199585, [7, 7]=1681199585, [9, 9]=1681199585, [3, 3]=1681199585, [1, 1]=1681199585, [15, 15]=1681199585, [21, 21]=1681199585, [17, 17]=1681199585, [19, 19]=1681199585, [27, 27]=1681199585, [23, 23]=1681199585, [25, 25]=1681199585, [5, 5]=1681199585, [11, 11]=1681199585, [13, 13]=1681199585}, worker_resources:{NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703])=WorkerResources(mem_on_heap:3584.0, mem_off_heap:0.0, cpu:280.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=3584.0, cpu.pcore.percent=280.0, offheap.memory.mb=0.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:user)
2023-04-11 10:53:15.092 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:53:15.099 o.a.s.s.EvenScheduler timer [INFO] Available slots: [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6700, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6701, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6702, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6703]
2023-04-11 10:53:15.109 o.a.s.d.n.Nimbus timer [INFO] Reassigning WordCount-1-1681199456 to 3 slots
2023-04-11 10:53:15.110 o.a.s.d.n.Nimbus timer [INFO] Reassign executors: [[20, 20], [14, 14], [12, 12], [16, 16], [18, 18], [28, 28], [26, 26], [10, 10], [8, 8], [24, 24], [6, 6], [22, 22], [2, 2], [4, 4], [13, 13], [11, 11], [7, 7], [9, 9], [19, 19], [23, 23], [21, 21], [25, 25], [27, 27], [5, 5], [1, 1], [3, 3], [15, 15], [17, 17]]
2023-04-11 10:53:15.114 o.a.s.d.n.Nimbus timer [INFO] Fragmentation after scheduling is: 0.0 MB, 0 PCore CPUs
2023-04-11 10:53:15.115 o.a.s.d.n.Nimbus timer [INFO] Node Id: cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1 Total Mem: 4096.0, Used Mem: 3584.0, Available Mem: 512.0, Total CPU: 400.0, Used CPU: 280.0, Available CPU: 120.0, fragmented: false
2023-04-11 10:53:15.117 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id WordCount-1-1681199456: Assignment(master_code_dir:/home/user/Storm/Data/Storm, node_host:{cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=Ubuntu.myguest.virtualbox.org}, executor_node_port:{[20, 20]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [14, 14]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [12, 12]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [16, 16]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [18, 18]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [28, 28]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [26, 26]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [10, 10]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [8, 8]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [24, 24]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [6, 6]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [22, 22]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [2, 2]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [4, 4]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [13, 13]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [11, 11]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [7, 7]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [9, 9]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [19, 19]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [23, 23]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [21, 21]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [25, 25]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [27, 27]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [5, 5]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [1, 1]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [3, 3]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [15, 15]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [17, 17]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701])}, executor_start_time_secs:{[12, 12]=1681199595, [6, 6]=1681199595, [8, 8]=1681199595, [10, 10]=1681199595, [18, 18]=1681199595, [14, 14]=1681199595, [16, 16]=1681199595, [24, 24]=1681199595, [26, 26]=1681199595, [28, 28]=1681199595, [20, 20]=1681199595, [22, 22]=1681199595, [2, 2]=1681199595, [4, 4]=1681199595, [15, 15]=1681199595, [7, 7]=1681199595, [9, 9]=1681199595, [11, 11]=1681199595, [13, 13]=1681199595, [3, 3]=1681199595, [5, 5]=1681199595, [1, 1]=1681199595, [21, 21]=1681199595, [17, 17]=1681199595, [19, 19]=1681199595, [27, 27]=1681199595, [25, 25]=1681199595, [23, 23]=1681199595}, worker_resources:{NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702])=WorkerResources(mem_on_heap:1152.0, mem_off_heap:0.0, cpu:90.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1152.0, cpu.pcore.percent=90.0, offheap.memory.mb=0.0}, shared_resources:{}), NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701])=WorkerResources(mem_on_heap:1152.0, mem_off_heap:0.0, cpu:90.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1152.0, cpu.pcore.percent=90.0, offheap.memory.mb=0.0}, shared_resources:{}), NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700])=WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1280.0, cpu.pcore.percent=100.0, offheap.memory.mb=0.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:user)
2023-04-11 10:53:25.216 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:53:35.290 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:53:45.361 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:53:55.429 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:54:05.497 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:54:15.564 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:54:25.632 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:54:35.695 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:54:45.733 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:54:55.757 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:55:05.782 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:55:15.805 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[8, 8] not alive
2023-04-11 10:55:15.805 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[16, 16] not alive
2023-04-11 10:55:15.805 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[14, 14] not alive
2023-04-11 10:55:15.806 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[18, 18] not alive
2023-04-11 10:55:15.806 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[20, 20] not alive
2023-04-11 10:55:15.806 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[22, 22] not alive
2023-04-11 10:55:15.806 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[24, 24] not alive
2023-04-11 10:55:15.806 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[26, 26] not alive
2023-04-11 10:55:15.806 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[28, 28] not alive
2023-04-11 10:55:15.806 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[2, 2] not alive
2023-04-11 10:55:15.806 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[4, 4] not alive
2023-04-11 10:55:15.806 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[6, 6] not alive
2023-04-11 10:55:15.806 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[10, 10] not alive
2023-04-11 10:55:15.807 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[12, 12] not alive
2023-04-11 10:55:15.807 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[7, 7] not alive
2023-04-11 10:55:15.807 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[17, 17] not alive
2023-04-11 10:55:15.807 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[13, 13] not alive
2023-04-11 10:55:15.807 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[15, 15] not alive
2023-04-11 10:55:15.807 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[19, 19] not alive
2023-04-11 10:55:15.807 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[21, 21] not alive
2023-04-11 10:55:15.807 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[23, 23] not alive
2023-04-11 10:55:15.807 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[25, 25] not alive
2023-04-11 10:55:15.807 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[27, 27] not alive
2023-04-11 10:55:15.808 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[1, 1] not alive
2023-04-11 10:55:15.808 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[3, 3] not alive
2023-04-11 10:55:15.808 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[5, 5] not alive
2023-04-11 10:55:15.808 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[9, 9] not alive
2023-04-11 10:55:15.808 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[11, 11] not alive
2023-04-11 10:55:15.813 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:55:15.814 o.a.s.s.EvenScheduler timer [INFO] Available slots: [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6703]
2023-04-11 10:55:15.817 o.a.s.d.n.Nimbus timer [INFO] Reassigning WordCount-1-1681199456 to 1 slots
2023-04-11 10:55:15.817 o.a.s.d.n.Nimbus timer [INFO] Reassign executors: [[20, 20], [14, 14], [12, 12], [16, 16], [18, 18], [28, 28], [26, 26], [10, 10], [8, 8], [24, 24], [6, 6], [22, 22], [2, 2], [4, 4], [13, 13], [11, 11], [7, 7], [9, 9], [19, 19], [23, 23], [21, 21], [25, 25], [27, 27], [5, 5], [1, 1], [3, 3], [15, 15], [17, 17]]
2023-04-11 10:55:15.817 o.a.s.d.n.Nimbus timer [INFO] Fragmentation after scheduling is: 0.0 MB, 0 PCore CPUs
2023-04-11 10:55:15.817 o.a.s.d.n.Nimbus timer [INFO] Node Id: cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1 Total Mem: 4096.0, Used Mem: 3584.0, Available Mem: 512.0, Total CPU: 400.0, Used CPU: 280.0, Available CPU: 120.0, fragmented: false
2023-04-11 10:55:15.818 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id WordCount-1-1681199456: Assignment(master_code_dir:/home/user/Storm/Data/Storm, node_host:{cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=Ubuntu.myguest.virtualbox.org}, executor_node_port:{[20, 20]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [14, 14]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [12, 12]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [16, 16]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [18, 18]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [28, 28]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [26, 26]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [10, 10]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [8, 8]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [24, 24]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [6, 6]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [22, 22]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [2, 2]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [4, 4]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [13, 13]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [11, 11]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [7, 7]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [9, 9]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [19, 19]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [23, 23]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [21, 21]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [25, 25]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [27, 27]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [5, 5]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [1, 1]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [3, 3]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [15, 15]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [17, 17]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703])}, executor_start_time_secs:{[12, 12]=1681199715, [6, 6]=1681199715, [2, 2]=1681199715, [4, 4]=1681199715, [8, 8]=1681199715, [10, 10]=1681199715, [18, 18]=1681199715, [20, 20]=1681199715, [22, 22]=1681199715, [14, 14]=1681199715, [16, 16]=1681199715, [24, 24]=1681199715, [26, 26]=1681199715, [28, 28]=1681199715, [9, 9]=1681199715, [15, 15]=1681199715, [7, 7]=1681199715, [11, 11]=1681199715, [13, 13]=1681199715, [3, 3]=1681199715, [5, 5]=1681199715, [1, 1]=1681199715, [21, 21]=1681199715, [27, 27]=1681199715, [25, 25]=1681199715, [23, 23]=1681199715, [19, 19]=1681199715, [17, 17]=1681199715}, worker_resources:{NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703])=WorkerResources(mem_on_heap:3584.0, mem_off_heap:0.0, cpu:280.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=3584.0, cpu.pcore.percent=280.0, offheap.memory.mb=0.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:user)
2023-04-11 10:55:25.852 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:55:25.853 o.a.s.s.EvenScheduler timer [INFO] Available slots: [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6700, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6701, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6702, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6703]
2023-04-11 10:55:25.862 o.a.s.d.n.Nimbus timer [INFO] Reassigning WordCount-1-1681199456 to 3 slots
2023-04-11 10:55:25.862 o.a.s.d.n.Nimbus timer [INFO] Reassign executors: [[20, 20], [14, 14], [12, 12], [16, 16], [18, 18], [28, 28], [26, 26], [10, 10], [8, 8], [24, 24], [6, 6], [22, 22], [2, 2], [4, 4], [13, 13], [11, 11], [7, 7], [9, 9], [19, 19], [23, 23], [21, 21], [25, 25], [27, 27], [5, 5], [1, 1], [3, 3], [15, 15], [17, 17]]
2023-04-11 10:55:25.863 o.a.s.d.n.Nimbus timer [INFO] Fragmentation after scheduling is: 0.0 MB, 0 PCore CPUs
2023-04-11 10:55:25.863 o.a.s.d.n.Nimbus timer [INFO] Node Id: cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1 Total Mem: 4096.0, Used Mem: 3584.0, Available Mem: 512.0, Total CPU: 400.0, Used CPU: 280.0, Available CPU: 120.0, fragmented: false
2023-04-11 10:55:25.863 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id WordCount-1-1681199456: Assignment(master_code_dir:/home/user/Storm/Data/Storm, node_host:{cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=Ubuntu.myguest.virtualbox.org}, executor_node_port:{[20, 20]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [14, 14]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [12, 12]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [16, 16]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [18, 18]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [28, 28]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [26, 26]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [10, 10]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [8, 8]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [24, 24]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [6, 6]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [22, 22]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [2, 2]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [4, 4]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [13, 13]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [11, 11]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [7, 7]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [9, 9]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [19, 19]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [23, 23]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [21, 21]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [25, 25]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [27, 27]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [5, 5]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [1, 1]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [3, 3]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [15, 15]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [17, 17]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701])}, executor_start_time_secs:{[10, 10]=1681199725, [12, 12]=1681199725, [14, 14]=1681199725, [16, 16]=1681199725, [6, 6]=1681199725, [2, 2]=1681199725, [4, 4]=1681199725, [8, 8]=1681199725, [18, 18]=1681199725, [20, 20]=1681199725, [22, 22]=1681199725, [24, 24]=1681199725, [26, 26]=1681199725, [28, 28]=1681199725, [9, 9]=1681199725, [15, 15]=1681199725, [19, 19]=1681199725, [17, 17]=1681199725, [7, 7]=1681199725, [11, 11]=1681199725, [13, 13]=1681199725, [3, 3]=1681199725, [5, 5]=1681199725, [1, 1]=1681199725, [21, 21]=1681199725, [27, 27]=1681199725, [25, 25]=1681199725, [23, 23]=1681199725}, worker_resources:{NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702])=WorkerResources(mem_on_heap:1152.0, mem_off_heap:0.0, cpu:90.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1152.0, cpu.pcore.percent=90.0, offheap.memory.mb=0.0}, shared_resources:{}), NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701])=WorkerResources(mem_on_heap:1152.0, mem_off_heap:0.0, cpu:90.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1152.0, cpu.pcore.percent=90.0, offheap.memory.mb=0.0}, shared_resources:{}), NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700])=WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1280.0, cpu.pcore.percent=100.0, offheap.memory.mb=0.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:user)
2023-04-11 10:55:35.897 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:55:45.931 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:55:55.963 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:56:06.001 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:56:16.069 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:56:26.123 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:56:36.183 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:56:46.217 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:56:56.259 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:57:06.302 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:57:16.337 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:57:26.379 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[8, 8] not alive
2023-04-11 10:57:26.379 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[16, 16] not alive
2023-04-11 10:57:26.379 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[14, 14] not alive
2023-04-11 10:57:26.379 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[18, 18] not alive
2023-04-11 10:57:26.379 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[20, 20] not alive
2023-04-11 10:57:26.379 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[22, 22] not alive
2023-04-11 10:57:26.379 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[24, 24] not alive
2023-04-11 10:57:26.379 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[26, 26] not alive
2023-04-11 10:57:26.379 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[28, 28] not alive
2023-04-11 10:57:26.380 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[2, 2] not alive
2023-04-11 10:57:26.380 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[4, 4] not alive
2023-04-11 10:57:26.380 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[6, 6] not alive
2023-04-11 10:57:26.380 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[10, 10] not alive
2023-04-11 10:57:26.380 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[12, 12] not alive
2023-04-11 10:57:26.380 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[7, 7] not alive
2023-04-11 10:57:26.380 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[17, 17] not alive
2023-04-11 10:57:26.380 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[13, 13] not alive
2023-04-11 10:57:26.380 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[15, 15] not alive
2023-04-11 10:57:26.380 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[19, 19] not alive
2023-04-11 10:57:26.380 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[21, 21] not alive
2023-04-11 10:57:26.380 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[23, 23] not alive
2023-04-11 10:57:26.381 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[25, 25] not alive
2023-04-11 10:57:26.381 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[27, 27] not alive
2023-04-11 10:57:26.381 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[1, 1] not alive
2023-04-11 10:57:26.381 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[3, 3] not alive
2023-04-11 10:57:26.381 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[5, 5] not alive
2023-04-11 10:57:26.381 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[9, 9] not alive
2023-04-11 10:57:26.381 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[11, 11] not alive
2023-04-11 10:57:26.384 o.a.s.s.b.r.LogReporter timer [WARN] add supervisor cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1  to blacklist. The bad slot history of supervisors is : [{}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}]
2023-04-11 10:57:26.384 o.a.s.s.b.s.DefaultBlacklistStrategy timer [INFO] Need 3 slots more. Releasing some blacklisted nodes to cover it.
2023-04-11 10:57:26.384 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:57:26.385 o.a.s.s.EvenScheduler timer [INFO] Available slots: [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6703]
2023-04-11 10:57:26.388 o.a.s.d.n.Nimbus timer [INFO] Reassigning WordCount-1-1681199456 to 1 slots
2023-04-11 10:57:26.388 o.a.s.d.n.Nimbus timer [INFO] Reassign executors: [[20, 20], [14, 14], [12, 12], [16, 16], [18, 18], [28, 28], [26, 26], [10, 10], [8, 8], [24, 24], [6, 6], [22, 22], [2, 2], [4, 4], [13, 13], [11, 11], [7, 7], [9, 9], [19, 19], [23, 23], [21, 21], [25, 25], [27, 27], [5, 5], [1, 1], [3, 3], [15, 15], [17, 17]]
2023-04-11 10:57:26.389 o.a.s.d.n.Nimbus timer [INFO] Fragmentation after scheduling is: 0.0 MB, 0 PCore CPUs
2023-04-11 10:57:26.389 o.a.s.d.n.Nimbus timer [INFO] Node Id: cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1 Total Mem: 4096.0, Used Mem: 3584.0, Available Mem: 512.0, Total CPU: 400.0, Used CPU: 280.0, Available CPU: 120.0, fragmented: false
2023-04-11 10:57:26.389 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id WordCount-1-1681199456: Assignment(master_code_dir:/home/user/Storm/Data/Storm, node_host:{cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=Ubuntu.myguest.virtualbox.org}, executor_node_port:{[20, 20]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [14, 14]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [12, 12]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [16, 16]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [18, 18]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [28, 28]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [26, 26]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [10, 10]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [8, 8]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [24, 24]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [6, 6]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [22, 22]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [2, 2]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [4, 4]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [13, 13]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [11, 11]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [7, 7]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [9, 9]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [19, 19]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [23, 23]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [21, 21]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [25, 25]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [27, 27]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [5, 5]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [1, 1]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [3, 3]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [15, 15]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [17, 17]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703])}, executor_start_time_secs:{[12, 12]=1681199846, [10, 10]=1681199846, [14, 14]=1681199846, [16, 16]=1681199846, [6, 6]=1681199846, [2, 2]=1681199846, [4, 4]=1681199846, [8, 8]=1681199846, [18, 18]=1681199846, [20, 20]=1681199846, [22, 22]=1681199846, [24, 24]=1681199846, [26, 26]=1681199846, [28, 28]=1681199846, [9, 9]=1681199846, [15, 15]=1681199846, [19, 19]=1681199846, [21, 21]=1681199846, [23, 23]=1681199846, [27, 27]=1681199846, [25, 25]=1681199846, [17, 17]=1681199846, [7, 7]=1681199846, [11, 11]=1681199846, [13, 13]=1681199846, [3, 3]=1681199846, [1, 1]=1681199846, [5, 5]=1681199846}, worker_resources:{NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703])=WorkerResources(mem_on_heap:3584.0, mem_off_heap:0.0, cpu:280.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=3584.0, cpu.pcore.percent=280.0, offheap.memory.mb=0.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:user)
2023-04-11 10:57:36.432 o.a.s.s.b.r.LogReporter timer [WARN] add supervisor cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1  to blacklist. The bad slot history of supervisors is : [{}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}]
2023-04-11 10:57:36.435 o.a.s.s.b.s.DefaultBlacklistStrategy timer [INFO] Need 2 slots more. Releasing some blacklisted nodes to cover it.
2023-04-11 10:57:36.436 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:57:36.437 o.a.s.s.EvenScheduler timer [INFO] Available slots: [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6700, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6701, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6702, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6703]
2023-04-11 10:57:36.452 o.a.s.d.n.Nimbus timer [INFO] Reassigning WordCount-1-1681199456 to 3 slots
2023-04-11 10:57:36.453 o.a.s.d.n.Nimbus timer [INFO] Reassign executors: [[20, 20], [14, 14], [12, 12], [16, 16], [18, 18], [28, 28], [26, 26], [10, 10], [8, 8], [24, 24], [6, 6], [22, 22], [2, 2], [4, 4], [13, 13], [11, 11], [7, 7], [9, 9], [19, 19], [23, 23], [21, 21], [25, 25], [27, 27], [5, 5], [1, 1], [3, 3], [15, 15], [17, 17]]
2023-04-11 10:57:36.453 o.a.s.d.n.Nimbus timer [INFO] Fragmentation after scheduling is: 0.0 MB, 0 PCore CPUs
2023-04-11 10:57:36.454 o.a.s.d.n.Nimbus timer [INFO] Node Id: cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1 Total Mem: 4096.0, Used Mem: 3584.0, Available Mem: 512.0, Total CPU: 400.0, Used CPU: 280.0, Available CPU: 120.0, fragmented: false
2023-04-11 10:57:36.454 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id WordCount-1-1681199456: Assignment(master_code_dir:/home/user/Storm/Data/Storm, node_host:{cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=Ubuntu.myguest.virtualbox.org}, executor_node_port:{[20, 20]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [14, 14]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [12, 12]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [16, 16]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [18, 18]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [28, 28]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [26, 26]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [10, 10]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [8, 8]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [24, 24]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [6, 6]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [22, 22]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [2, 2]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [4, 4]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [13, 13]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [11, 11]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [7, 7]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [9, 9]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [19, 19]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [23, 23]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [21, 21]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [25, 25]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [27, 27]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [5, 5]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [1, 1]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [3, 3]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [15, 15]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [17, 17]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701])}, executor_start_time_secs:{[12, 12]=1681199856, [10, 10]=1681199856, [14, 14]=1681199856, [16, 16]=1681199856, [6, 6]=1681199856, [2, 2]=1681199856, [4, 4]=1681199856, [8, 8]=1681199856, [18, 18]=1681199856, [20, 20]=1681199856, [22, 22]=1681199856, [24, 24]=1681199856, [26, 26]=1681199856, [28, 28]=1681199856, [15, 15]=1681199856, [9, 9]=1681199856, [11, 11]=1681199856, [13, 13]=1681199856, [19, 19]=1681199856, [21, 21]=1681199856, [23, 23]=1681199856, [27, 27]=1681199856, [25, 25]=1681199856, [17, 17]=1681199856, [7, 7]=1681199856, [5, 5]=1681199856, [3, 3]=1681199856, [1, 1]=1681199856}, worker_resources:{NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702])=WorkerResources(mem_on_heap:1152.0, mem_off_heap:0.0, cpu:90.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1152.0, cpu.pcore.percent=90.0, offheap.memory.mb=0.0}, shared_resources:{}), NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701])=WorkerResources(mem_on_heap:1152.0, mem_off_heap:0.0, cpu:90.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1152.0, cpu.pcore.percent=90.0, offheap.memory.mb=0.0}, shared_resources:{}), NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700])=WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1280.0, cpu.pcore.percent=100.0, offheap.memory.mb=0.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:user)
2023-04-11 10:57:46.495 o.a.s.s.b.r.LogReporter timer [WARN] add supervisor cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1  to blacklist. The bad slot history of supervisors is : [{}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}]
2023-04-11 10:57:46.496 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 10:57:56.549 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 10:58:06.602 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 10:58:16.672 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 10:58:26.741 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 10:58:36.780 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 10:58:46.842 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 10:58:56.908 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 10:59:06.951 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 10:59:16.974 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 10:59:27.002 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 10:59:37.033 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[8, 8] not alive
2023-04-11 10:59:37.034 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[16, 16] not alive
2023-04-11 10:59:37.034 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[14, 14] not alive
2023-04-11 10:59:37.035 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[18, 18] not alive
2023-04-11 10:59:37.035 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[20, 20] not alive
2023-04-11 10:59:37.036 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[22, 22] not alive
2023-04-11 10:59:37.036 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[24, 24] not alive
2023-04-11 10:59:37.036 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[26, 26] not alive
2023-04-11 10:59:37.037 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[28, 28] not alive
2023-04-11 10:59:37.037 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[2, 2] not alive
2023-04-11 10:59:37.037 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[4, 4] not alive
2023-04-11 10:59:37.038 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[6, 6] not alive
2023-04-11 10:59:37.038 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[10, 10] not alive
2023-04-11 10:59:37.039 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[12, 12] not alive
2023-04-11 10:59:37.039 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[7, 7] not alive
2023-04-11 10:59:37.039 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[17, 17] not alive
2023-04-11 10:59:37.040 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[13, 13] not alive
2023-04-11 10:59:37.040 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[15, 15] not alive
2023-04-11 10:59:37.040 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[19, 19] not alive
2023-04-11 10:59:37.041 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[21, 21] not alive
2023-04-11 10:59:37.041 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[23, 23] not alive
2023-04-11 10:59:37.041 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[25, 25] not alive
2023-04-11 10:59:37.042 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[27, 27] not alive
2023-04-11 10:59:37.042 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[1, 1] not alive
2023-04-11 10:59:37.042 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[3, 3] not alive
2023-04-11 10:59:37.043 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[5, 5] not alive
2023-04-11 10:59:37.043 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[9, 9] not alive
2023-04-11 10:59:37.044 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[11, 11] not alive
2023-04-11 10:59:37.052 o.a.s.s.b.s.DefaultBlacklistStrategy timer [INFO] Need 3 slots more. Releasing some blacklisted nodes to cover it.
2023-04-11 10:59:37.053 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:59:37.053 o.a.s.s.EvenScheduler timer [INFO] Available slots: [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6703]
2023-04-11 10:59:37.072 o.a.s.d.n.Nimbus timer [INFO] Reassigning WordCount-1-1681199456 to 1 slots
2023-04-11 10:59:37.072 o.a.s.d.n.Nimbus timer [INFO] Reassign executors: [[20, 20], [14, 14], [12, 12], [16, 16], [18, 18], [28, 28], [26, 26], [10, 10], [8, 8], [24, 24], [6, 6], [22, 22], [2, 2], [4, 4], [13, 13], [11, 11], [7, 7], [9, 9], [19, 19], [23, 23], [21, 21], [25, 25], [27, 27], [5, 5], [1, 1], [3, 3], [15, 15], [17, 17]]
2023-04-11 10:59:37.073 o.a.s.d.n.Nimbus timer [INFO] Fragmentation after scheduling is: 0.0 MB, 0 PCore CPUs
2023-04-11 10:59:37.073 o.a.s.d.n.Nimbus timer [INFO] Node Id: cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1 Total Mem: 4096.0, Used Mem: 3584.0, Available Mem: 512.0, Total CPU: 400.0, Used CPU: 280.0, Available CPU: 120.0, fragmented: false
2023-04-11 10:59:37.073 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id WordCount-1-1681199456: Assignment(master_code_dir:/home/user/Storm/Data/Storm, node_host:{cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=Ubuntu.myguest.virtualbox.org}, executor_node_port:{[20, 20]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [14, 14]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [12, 12]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [16, 16]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [18, 18]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [28, 28]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [26, 26]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [10, 10]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [8, 8]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [24, 24]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [6, 6]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [22, 22]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [2, 2]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [4, 4]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [13, 13]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [11, 11]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [7, 7]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [9, 9]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [19, 19]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [23, 23]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [21, 21]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [25, 25]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [27, 27]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [5, 5]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [1, 1]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [3, 3]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [15, 15]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [17, 17]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703])}, executor_start_time_secs:{[12, 12]=1681199977, [10, 10]=1681199977, [14, 14]=1681199977, [16, 16]=1681199977, [6, 6]=1681199977, [2, 2]=1681199977, [4, 4]=1681199977, [8, 8]=1681199977, [18, 18]=1681199977, [20, 20]=1681199977, [22, 22]=1681199977, [24, 24]=1681199977, [26, 26]=1681199977, [28, 28]=1681199977, [15, 15]=1681199977, [9, 9]=1681199977, [7, 7]=1681199977, [5, 5]=1681199977, [3, 3]=1681199977, [1, 1]=1681199977, [11, 11]=1681199977, [13, 13]=1681199977, [19, 19]=1681199977, [17, 17]=1681199977, [21, 21]=1681199977, [23, 23]=1681199977, [27, 27]=1681199977, [25, 25]=1681199977}, worker_resources:{NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703])=WorkerResources(mem_on_heap:3584.0, mem_off_heap:0.0, cpu:280.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=3584.0, cpu.pcore.percent=280.0, offheap.memory.mb=0.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:user)
2023-04-11 10:59:47.122 o.a.s.s.b.r.LogReporter timer [WARN] add supervisor cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1  to blacklist. The bad slot history of supervisors is : [{}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}]
2023-04-11 10:59:47.124 o.a.s.s.b.s.DefaultBlacklistStrategy timer [INFO] Need 2 slots more. Releasing some blacklisted nodes to cover it.
2023-04-11 10:59:47.124 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 10:59:47.125 o.a.s.s.EvenScheduler timer [INFO] Available slots: [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6700, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6701, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6702, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6703]
2023-04-11 10:59:47.131 o.a.s.d.n.Nimbus timer [INFO] Reassigning WordCount-1-1681199456 to 3 slots
2023-04-11 10:59:47.132 o.a.s.d.n.Nimbus timer [INFO] Reassign executors: [[20, 20], [14, 14], [12, 12], [16, 16], [18, 18], [28, 28], [26, 26], [10, 10], [8, 8], [24, 24], [6, 6], [22, 22], [2, 2], [4, 4], [13, 13], [11, 11], [7, 7], [9, 9], [19, 19], [23, 23], [21, 21], [25, 25], [27, 27], [5, 5], [1, 1], [3, 3], [15, 15], [17, 17]]
2023-04-11 10:59:47.133 o.a.s.d.n.Nimbus timer [INFO] Fragmentation after scheduling is: 0.0 MB, 0 PCore CPUs
2023-04-11 10:59:47.133 o.a.s.d.n.Nimbus timer [INFO] Node Id: cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1 Total Mem: 4096.0, Used Mem: 3584.0, Available Mem: 512.0, Total CPU: 400.0, Used CPU: 280.0, Available CPU: 120.0, fragmented: false
2023-04-11 10:59:47.134 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id WordCount-1-1681199456: Assignment(master_code_dir:/home/user/Storm/Data/Storm, node_host:{cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=Ubuntu.myguest.virtualbox.org}, executor_node_port:{[20, 20]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [14, 14]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [12, 12]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [16, 16]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [18, 18]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [28, 28]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [26, 26]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [10, 10]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [8, 8]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [24, 24]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [6, 6]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [22, 22]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [2, 2]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [4, 4]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [13, 13]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [11, 11]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [7, 7]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [9, 9]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [19, 19]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [23, 23]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [21, 21]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [25, 25]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [27, 27]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [5, 5]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [1, 1]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [3, 3]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [15, 15]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [17, 17]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701])}, executor_start_time_secs:{[12, 12]=1681199987, [10, 10]=1681199987, [14, 14]=1681199987, [16, 16]=1681199987, [6, 6]=1681199987, [2, 2]=1681199987, [4, 4]=1681199987, [8, 8]=1681199987, [18, 18]=1681199987, [20, 20]=1681199987, [22, 22]=1681199987, [24, 24]=1681199987, [26, 26]=1681199987, [28, 28]=1681199987, [9, 9]=1681199987, [15, 15]=1681199987, [7, 7]=1681199987, [5, 5]=1681199987, [3, 3]=1681199987, [1, 1]=1681199987, [11, 11]=1681199987, [13, 13]=1681199987, [19, 19]=1681199987, [21, 21]=1681199987, [23, 23]=1681199987, [27, 27]=1681199987, [25, 25]=1681199987, [17, 17]=1681199987}, worker_resources:{NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702])=WorkerResources(mem_on_heap:1152.0, mem_off_heap:0.0, cpu:90.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1152.0, cpu.pcore.percent=90.0, offheap.memory.mb=0.0}, shared_resources:{}), NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701])=WorkerResources(mem_on_heap:1152.0, mem_off_heap:0.0, cpu:90.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1152.0, cpu.pcore.percent=90.0, offheap.memory.mb=0.0}, shared_resources:{}), NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700])=WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1280.0, cpu.pcore.percent=100.0, offheap.memory.mb=0.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:user)
2023-04-11 10:59:57.193 o.a.s.s.b.r.LogReporter timer [WARN] add supervisor cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1  to blacklist. The bad slot history of supervisors is : [{}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}]
2023-04-11 10:59:57.196 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:00:07.249 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:00:17.303 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:00:27.351 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:00:37.379 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:00:47.423 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:00:57.451 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:01:07.481 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:01:17.512 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:01:27.537 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:01:37.569 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:01:47.612 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[8, 8] not alive
2023-04-11 11:01:47.613 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[16, 16] not alive
2023-04-11 11:01:47.613 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[14, 14] not alive
2023-04-11 11:01:47.614 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[18, 18] not alive
2023-04-11 11:01:47.614 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[20, 20] not alive
2023-04-11 11:01:47.614 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[22, 22] not alive
2023-04-11 11:01:47.615 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[24, 24] not alive
2023-04-11 11:01:47.615 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[26, 26] not alive
2023-04-11 11:01:47.615 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[28, 28] not alive
2023-04-11 11:01:47.616 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[2, 2] not alive
2023-04-11 11:01:47.616 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[4, 4] not alive
2023-04-11 11:01:47.616 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[6, 6] not alive
2023-04-11 11:01:47.616 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[10, 10] not alive
2023-04-11 11:01:47.617 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[12, 12] not alive
2023-04-11 11:01:47.617 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[7, 7] not alive
2023-04-11 11:01:47.617 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[17, 17] not alive
2023-04-11 11:01:47.617 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[13, 13] not alive
2023-04-11 11:01:47.618 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[15, 15] not alive
2023-04-11 11:01:47.618 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[19, 19] not alive
2023-04-11 11:01:47.618 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[21, 21] not alive
2023-04-11 11:01:47.619 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[23, 23] not alive
2023-04-11 11:01:47.619 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[25, 25] not alive
2023-04-11 11:01:47.620 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[27, 27] not alive
2023-04-11 11:01:47.620 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[1, 1] not alive
2023-04-11 11:01:47.620 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[3, 3] not alive
2023-04-11 11:01:47.620 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[5, 5] not alive
2023-04-11 11:01:47.621 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[9, 9] not alive
2023-04-11 11:01:47.621 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[11, 11] not alive
2023-04-11 11:01:47.629 o.a.s.s.b.s.DefaultBlacklistStrategy timer [INFO] Need 3 slots more. Releasing some blacklisted nodes to cover it.
2023-04-11 11:01:47.629 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 11:01:47.630 o.a.s.s.EvenScheduler timer [INFO] Available slots: [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6703]
2023-04-11 11:01:47.641 o.a.s.d.n.Nimbus timer [INFO] Reassigning WordCount-1-1681199456 to 1 slots
2023-04-11 11:01:47.641 o.a.s.d.n.Nimbus timer [INFO] Reassign executors: [[20, 20], [14, 14], [12, 12], [16, 16], [18, 18], [28, 28], [26, 26], [10, 10], [8, 8], [24, 24], [6, 6], [22, 22], [2, 2], [4, 4], [13, 13], [11, 11], [7, 7], [9, 9], [19, 19], [23, 23], [21, 21], [25, 25], [27, 27], [5, 5], [1, 1], [3, 3], [15, 15], [17, 17]]
2023-04-11 11:01:47.643 o.a.s.d.n.Nimbus timer [INFO] Fragmentation after scheduling is: 0.0 MB, 0 PCore CPUs
2023-04-11 11:01:47.644 o.a.s.d.n.Nimbus timer [INFO] Node Id: cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1 Total Mem: 4096.0, Used Mem: 3584.0, Available Mem: 512.0, Total CPU: 400.0, Used CPU: 280.0, Available CPU: 120.0, fragmented: false
2023-04-11 11:01:47.644 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id WordCount-1-1681199456: Assignment(master_code_dir:/home/user/Storm/Data/Storm, node_host:{cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=Ubuntu.myguest.virtualbox.org}, executor_node_port:{[20, 20]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [14, 14]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [12, 12]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [16, 16]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [18, 18]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [28, 28]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [26, 26]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [10, 10]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [8, 8]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [24, 24]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [6, 6]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [22, 22]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [2, 2]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [4, 4]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [13, 13]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [11, 11]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [7, 7]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [9, 9]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [19, 19]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [23, 23]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [21, 21]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [25, 25]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [27, 27]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [5, 5]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [1, 1]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [3, 3]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [15, 15]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [17, 17]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703])}, executor_start_time_secs:{[12, 12]=1681200107, [10, 10]=1681200107, [14, 14]=1681200107, [16, 16]=1681200107, [6, 6]=1681200107, [2, 2]=1681200107, [4, 4]=1681200107, [8, 8]=1681200107, [18, 18]=1681200107, [20, 20]=1681200107, [22, 22]=1681200107, [24, 24]=1681200107, [26, 26]=1681200107, [28, 28]=1681200107, [9, 9]=1681200107, [15, 15]=1681200107, [17, 17]=1681200107, [7, 7]=1681200107, [5, 5]=1681200107, [3, 3]=1681200107, [1, 1]=1681200107, [11, 11]=1681200107, [13, 13]=1681200107, [19, 19]=1681200107, [21, 21]=1681200107, [23, 23]=1681200107, [27, 27]=1681200107, [25, 25]=1681200107}, worker_resources:{NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703])=WorkerResources(mem_on_heap:3584.0, mem_off_heap:0.0, cpu:280.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=3584.0, cpu.pcore.percent=280.0, offheap.memory.mb=0.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:user)
2023-04-11 11:01:51.467 o.a.s.d.n.Nimbus pool-29-thread-29 [INFO] Latest profile actions for topology WordCount-1-1681199456 component count []
2023-04-11 11:01:57.681 o.a.s.s.b.r.LogReporter timer [WARN] add supervisor cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1  to blacklist. The bad slot history of supervisors is : [{}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}]
2023-04-11 11:01:57.681 o.a.s.s.b.s.DefaultBlacklistStrategy timer [INFO] Need 2 slots more. Releasing some blacklisted nodes to cover it.
2023-04-11 11:01:57.682 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 11:01:57.682 o.a.s.s.EvenScheduler timer [INFO] Available slots: [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6700, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6701, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6702, cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6703]
2023-04-11 11:01:57.686 o.a.s.d.n.Nimbus timer [INFO] Reassigning WordCount-1-1681199456 to 3 slots
2023-04-11 11:01:57.686 o.a.s.d.n.Nimbus timer [INFO] Reassign executors: [[20, 20], [14, 14], [12, 12], [16, 16], [18, 18], [28, 28], [26, 26], [10, 10], [8, 8], [24, 24], [6, 6], [22, 22], [2, 2], [4, 4], [13, 13], [11, 11], [7, 7], [9, 9], [19, 19], [23, 23], [21, 21], [25, 25], [27, 27], [5, 5], [1, 1], [3, 3], [15, 15], [17, 17]]
2023-04-11 11:01:57.687 o.a.s.d.n.Nimbus timer [INFO] Fragmentation after scheduling is: 0.0 MB, 0 PCore CPUs
2023-04-11 11:01:57.687 o.a.s.d.n.Nimbus timer [INFO] Node Id: cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1 Total Mem: 4096.0, Used Mem: 3584.0, Available Mem: 512.0, Total CPU: 400.0, Used CPU: 280.0, Available CPU: 120.0, fragmented: false
2023-04-11 11:01:57.687 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id WordCount-1-1681199456: Assignment(master_code_dir:/home/user/Storm/Data/Storm, node_host:{cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=Ubuntu.myguest.virtualbox.org}, executor_node_port:{[20, 20]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [14, 14]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [12, 12]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [16, 16]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [18, 18]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [28, 28]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [26, 26]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [10, 10]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [8, 8]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [24, 24]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [6, 6]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [22, 22]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [2, 2]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [4, 4]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [13, 13]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [11, 11]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [7, 7]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [9, 9]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [19, 19]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [23, 23]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [21, 21]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [25, 25]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [27, 27]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [5, 5]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701]), [1, 1]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700]), [3, 3]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [15, 15]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702]), [17, 17]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701])}, executor_start_time_secs:{[12, 12]=1681200117, [10, 10]=1681200117, [14, 14]=1681200117, [16, 16]=1681200117, [6, 6]=1681200117, [2, 2]=1681200117, [4, 4]=1681200117, [8, 8]=1681200117, [18, 18]=1681200117, [20, 20]=1681200117, [22, 22]=1681200117, [24, 24]=1681200117, [26, 26]=1681200117, [28, 28]=1681200117, [15, 15]=1681200117, [9, 9]=1681200117, [17, 17]=1681200117, [19, 19]=1681200117, [21, 21]=1681200117, [23, 23]=1681200117, [27, 27]=1681200117, [25, 25]=1681200117, [7, 7]=1681200117, [5, 5]=1681200117, [3, 3]=1681200117, [1, 1]=1681200117, [11, 11]=1681200117, [13, 13]=1681200117}, worker_resources:{NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6702])=WorkerResources(mem_on_heap:1152.0, mem_off_heap:0.0, cpu:90.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1152.0, cpu.pcore.percent=90.0, offheap.memory.mb=0.0}, shared_resources:{}), NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6701])=WorkerResources(mem_on_heap:1152.0, mem_off_heap:0.0, cpu:90.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1152.0, cpu.pcore.percent=90.0, offheap.memory.mb=0.0}, shared_resources:{}), NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6700])=WorkerResources(mem_on_heap:1280.0, mem_off_heap:0.0, cpu:100.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=1280.0, cpu.pcore.percent=100.0, offheap.memory.mb=0.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:user)
2023-04-11 11:02:07.718 o.a.s.s.b.r.LogReporter timer [WARN] add supervisor cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1  to blacklist. The bad slot history of supervisors is : [{}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=[6700, 6701, 6702]}, {}, {}]
2023-04-11 11:02:07.718 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:02:17.809 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:02:27.860 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:02:37.891 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:02:47.922 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:02:57.980 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:03:08.026 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:03:18.077 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:03:28.131 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:03:38.179 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:03:48.200 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1] are blacklisted.
2023-04-11 11:03:58.220 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[8, 8] not alive
2023-04-11 11:03:58.220 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[16, 16] not alive
2023-04-11 11:03:58.221 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[14, 14] not alive
2023-04-11 11:03:58.221 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[18, 18] not alive
2023-04-11 11:03:58.221 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[20, 20] not alive
2023-04-11 11:03:58.221 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[22, 22] not alive
2023-04-11 11:03:58.221 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[24, 24] not alive
2023-04-11 11:03:58.221 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[26, 26] not alive
2023-04-11 11:03:58.221 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[28, 28] not alive
2023-04-11 11:03:58.221 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[2, 2] not alive
2023-04-11 11:03:58.221 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[4, 4] not alive
2023-04-11 11:03:58.222 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[6, 6] not alive
2023-04-11 11:03:58.222 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[10, 10] not alive
2023-04-11 11:03:58.222 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[12, 12] not alive
2023-04-11 11:03:58.222 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[7, 7] not alive
2023-04-11 11:03:58.222 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[17, 17] not alive
2023-04-11 11:03:58.222 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[13, 13] not alive
2023-04-11 11:03:58.222 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[15, 15] not alive
2023-04-11 11:03:58.222 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[19, 19] not alive
2023-04-11 11:03:58.222 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[21, 21] not alive
2023-04-11 11:03:58.222 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[23, 23] not alive
2023-04-11 11:03:58.223 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[25, 25] not alive
2023-04-11 11:03:58.223 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[27, 27] not alive
2023-04-11 11:03:58.225 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[1, 1] not alive
2023-04-11 11:03:58.225 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[3, 3] not alive
2023-04-11 11:03:58.225 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[5, 5] not alive
2023-04-11 11:03:58.225 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[9, 9] not alive
2023-04-11 11:03:58.225 o.a.s.d.n.HeartbeatCache timer [INFO] Executor WordCount-1-1681199456:[11, 11] not alive
2023-04-11 11:03:58.228 o.a.s.s.b.s.DefaultBlacklistStrategy timer [INFO] Need 3 slots more. Releasing some blacklisted nodes to cover it.
2023-04-11 11:03:58.229 o.a.s.s.b.BlacklistScheduler timer [INFO] Supervisors [] are blacklisted.
2023-04-11 11:03:58.229 o.a.s.s.EvenScheduler timer [INFO] Available slots: [cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1:6703]
2023-04-11 11:03:58.234 o.a.s.d.n.Nimbus timer [INFO] Reassigning WordCount-1-1681199456 to 1 slots
2023-04-11 11:03:58.234 o.a.s.d.n.Nimbus timer [INFO] Reassign executors: [[20, 20], [14, 14], [12, 12], [16, 16], [18, 18], [28, 28], [26, 26], [10, 10], [8, 8], [24, 24], [6, 6], [22, 22], [2, 2], [4, 4], [13, 13], [11, 11], [7, 7], [9, 9], [19, 19], [23, 23], [21, 21], [25, 25], [27, 27], [5, 5], [1, 1], [3, 3], [15, 15], [17, 17]]
2023-04-11 11:03:58.235 o.a.s.d.n.Nimbus timer [INFO] Fragmentation after scheduling is: 0.0 MB, 0 PCore CPUs
2023-04-11 11:03:58.235 o.a.s.d.n.Nimbus timer [INFO] Node Id: cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1 Total Mem: 4096.0, Used Mem: 3584.0, Available Mem: 512.0, Total CPU: 400.0, Used CPU: 280.0, Available CPU: 120.0, fragmented: false
2023-04-11 11:03:58.235 o.a.s.d.n.Nimbus timer [INFO] Setting new assignment for topology id WordCount-1-1681199456: Assignment(master_code_dir:/home/user/Storm/Data/Storm, node_host:{cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1=Ubuntu.myguest.virtualbox.org}, executor_node_port:{[20, 20]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [14, 14]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [12, 12]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [16, 16]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [18, 18]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [28, 28]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [26, 26]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [10, 10]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [8, 8]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [24, 24]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [6, 6]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [22, 22]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [2, 2]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [4, 4]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [13, 13]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [11, 11]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [7, 7]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [9, 9]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [19, 19]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [23, 23]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [21, 21]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [25, 25]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [27, 27]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [5, 5]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [1, 1]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [3, 3]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [15, 15]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703]), [17, 17]=NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703])}, executor_start_time_secs:{[12, 12]=1681200238, [10, 10]=1681200238, [14, 14]=1681200238, [16, 16]=1681200238, [6, 6]=1681200238, [2, 2]=1681200238, [4, 4]=1681200238, [8, 8]=1681200238, [18, 18]=1681200238, [20, 20]=1681200238, [22, 22]=1681200238, [24, 24]=1681200238, [26, 26]=1681200238, [28, 28]=1681200238, [19, 19]=1681200238, [15, 15]=1681200238, [9, 9]=1681200238, [11, 11]=1681200238, [13, 13]=1681200238, [17, 17]=1681200238, [21, 21]=1681200238, [23, 23]=1681200238, [27, 27]=1681200238, [25, 25]=1681200238, [7, 7]=1681200238, [5, 5]=1681200238, [3, 3]=1681200238, [1, 1]=1681200238}, worker_resources:{NodeInfo(node:cd7c12c1-0e2f-4621-97ec-5703e8811151-127.0.1.1, port:[6703])=WorkerResources(mem_on_heap:3584.0, mem_off_heap:0.0, cpu:280.0, shared_mem_on_heap:0.0, shared_mem_off_heap:0.0, resources:{onheap.memory.mb=3584.0, cpu.pcore.percent=280.0, offheap.memory.mb=0.0}, shared_resources:{})}, total_shared_off_heap:{}, owner:user)
2023-04-11 11:04:06.823 o.a.s.u.Utils ShutdownHook-sleepKill-10s [INFO] Halting after 10 seconds
2023-04-11 11:04:06.835 o.a.s.d.n.Nimbus ShutdownHook-shutdownFunc [INFO] Shutting down master
2023-04-11 11:04:06.836 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 11:04:06.947 o.a.s.s.o.a.z.ZooKeeper ShutdownHook-shutdownFunc [INFO] Session: 0x1000011fa01000d closed
2023-04-11 11:04:06.947 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa01000d
2023-04-11 11:04:06.951 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 11:04:07.068 o.a.s.s.o.a.z.ZooKeeper ShutdownHook-shutdownFunc [INFO] Session: 0x1000011fa01000e closed
2023-04-11 11:04:07.069 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa01000e
2023-04-11 11:04:07.072 o.a.s.s.b.BlacklistScheduler ShutdownHook-shutdownFunc [INFO] Cleanup black list scheduler
2023-04-11 11:04:07.073 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 11:04:07.183 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa010010
2023-04-11 11:04:07.184 o.a.s.s.o.a.z.ZooKeeper ShutdownHook-shutdownFunc [INFO] Session: 0x1000011fa010010 closed
2023-04-11 11:04:07.188 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 11:04:07.311 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa010012
2023-04-11 11:04:07.312 o.a.s.s.o.a.z.ZooKeeper ShutdownHook-shutdownFunc [INFO] Session: 0x1000011fa010012 closed
2023-04-11 11:04:07.313 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 11:04:07.421 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa010013
2023-04-11 11:04:07.422 o.a.s.s.o.a.z.ZooKeeper ShutdownHook-shutdownFunc [INFO] Session: 0x1000011fa010013 closed
2023-04-11 11:04:07.440 o.a.s.z.LeaderElectorImp ShutdownHook-shutdownFunc [INFO] Removed from leader lock queue.
2023-04-11 11:04:07.449 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-04-11 11:04:07.557 o.a.s.s.o.a.z.ZooKeeper ShutdownHook-shutdownFunc [INFO] Session: 0x1000011fa01000f closed
2023-04-11 11:04:07.557 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000011fa01000f
2023-04-11 11:04:07.571 o.a.s.d.n.Nimbus ShutdownHook-shutdownFunc [INFO] Shut down master
